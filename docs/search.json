[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Welcome to My Analytics Lab",
    "section": "",
    "text": "Hello!! My name is Ece Çavuşgil.\nThis is my personal webpage.\nPlease stay tuned to follow my works on data analytics, blog posts, and more.\n\n\n\n Back to top"
  },
  {
    "objectID": "project.html",
    "href": "project.html",
    "title": "Is Ignorance Truly Bliss*? Relationship between Education, Gender & Happiness",
    "section": "",
    "text": "The phrase “Ignorance is bliss is a perspective that most of us have come across at least once, and sometimes even found meaningful. Naturally, individuals may have developed and educated themselves regardless of their formal educational background, gaining the ability to view life from different perspectives. However, in this study, the concept of ‘ignorance’ that I aim to focus on is independent of such interpretations. Instead, it refers to the relationship between a person’s level of education and their happiness, as well as how this relationship differs between men and women.\nProblem Definition: Life satisfaction among individuals may vary depending on factors such as gender and education level. Therefore, it is necessary to conduct an analysis to examine the direction and magnitude of this interaction and to observe how happiness levels change based on individuals’ gender and educational background. The aim of this study is to reveal whether there is a significant relationship between educational attainment and happiness levels in this context."
  },
  {
    "objectID": "project.html#data-source",
    "href": "project.html#data-source",
    "title": "Is Ignorance Truly Bliss*? Relationship between Education, Gender & Happiness",
    "section": "2.1 Data Source",
    "text": "2.1 Data Source\nIn this study, data obtained from the following links conducted by the Turkish Statistical Institute (TURKSTAT) has been used.\n\nLife Satisfaction Survey1\nPopulation Statistics Portal2"
  },
  {
    "objectID": "project.html#general-information-about-data",
    "href": "project.html#general-information-about-data",
    "title": "Is Ignorance Truly Bliss*? Relationship between Education, Gender & Happiness",
    "section": "2.2 General Information About Data",
    "text": "2.2 General Information About Data\n“education” dataset: This dataset contains the number of individuals by gender and educational status for each province between 2008 and 2023.A small part of the dataset is shown below.\n\n\nShow the code\n#libraries\nlibrary(readxl)\nlibrary(ggplot2)\nlibrary(tidyverse)\n\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.4     ✔ readr     2.1.5\n✔ forcats   1.0.0     ✔ stringr   1.5.1\n✔ lubridate 1.9.3     ✔ tibble    3.2.1\n✔ purrr     1.0.2     ✔ tidyr     1.3.1\n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\n\nShow the code\nlibrary(dslabs)\nlibrary(ggthemes)\nlibrary(ggrepel)\nlibrary(dplyr)\nlibrary(gganimate)\nlibrary(sf)\n\n\nLinking to GEOS 3.9.3, GDAL 3.5.2, PROJ 8.2.1; sf_use_s2() is TRUE\n\n\nShow the code\nlibrary(viridis)\n\n\nLoading required package: viridisLite\n\n\nShow the code\nlibrary(broom)\nlibrary(htmlwidgets)\nlibrary(knitr)\nlibrary(gifski)\nlibrary(tidytext)\nlibrary(nortest)\n\n#Import education dataset\n\n#education &lt;- read_excel(\"education.xlsx\")\n#save(education,file = \"education.RData\")\nload(\"education.RData\")\nhead(education)\n\n\n# A tibble: 6 × 8\n  Year  Province Educational_Status          Total   Male Female Percentage_Male\n  &lt;chr&gt; &lt;chr&gt;    &lt;chr&gt;                       &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;           &lt;dbl&gt;\n1 2023  ADANA    Okuma yazma bilmeyen        58357  10083  48274             1  \n2 2023  ADANA    Okuma yazma bilen fakat b… 219571  95506 124065             9.2\n3 2023  ADANA    İlkokul                    441425 190047 251378            18.4\n4 2023  ADANA    Ortaokul veya dengi mesle… 384900 208582 176318            20.2\n5 2023  ADANA    İlköğretim                 132788  80203  52585             7.8\n6 2023  ADANA    Lise veya dengi meslek ok… 484355 268172 216183            25.9\n# ℹ 1 more variable: Percentage_Female &lt;dbl&gt;\n\n\n“byeducation” dataset: This dataset contains the percentages of general happiness levels by educational status between 2004 and 2024. A small part of the dataset is shown below.\n\n\nShow the code\n#Import byeducation dataset\n#byeducation &lt;- read_excel(\"byeducation.xlsx\")\n#save(byeducation,file = \"byeducation.RData\")\nload(\"byeducation.RData\")\nhead(byeducation)\n\n\n# A tibble: 6 × 7\n   Year Happiness_Level           `No School Completed` `Primary  School`\n  &lt;dbl&gt; &lt;chr&gt;                                     &lt;dbl&gt;             &lt;dbl&gt;\n1  2004 Happy                                      54.4              57.7\n2  2004 Neither happy nor unhappy                  27                30.7\n3  2004 Unhappy                                    18.6              11.6\n4  2005 Happy                                      54                55.2\n5  2005 Neither happy nor unhappy                  27.8              31.8\n6  2005 Unhappy                                    18.1              13.1\n# ℹ 3 more variables: `Primary Education or Junior High School` &lt;dbl&gt;,\n#   `High School or Equivalent` &lt;dbl&gt;, `Higher Education` &lt;dbl&gt;\n\n\n“bygender” data set: This dataset contains the percentages of general happiness levels by gender between 2003 and 2024. A small part of the dataset is shown below.\n\n\nShow the code\n#Import bygender dataset\n#bygender &lt;- read_excel(\"bygender.xlsx\")\n#save(bygender,file = \"bygender.RData\")\nload(\"bygender.RData\")\nhead(bygender)\n\n\n# A tibble: 6 × 5\n   Year Happiness_Level           Total  Male Female\n  &lt;dbl&gt; &lt;chr&gt;                     &lt;dbl&gt; &lt;dbl&gt;  &lt;dbl&gt;\n1  2003 Very happy                 12    12.4   11.6\n2  2003 Happy                      47.6  45.7   49.4\n3  2003 Neither happy nor unhappy  33.2  34.1   32.2\n4  2003 Unhappy                     5.6   6.2    5  \n5  2003 Very unhappy                1.7   1.5    1.8\n6  2004 Very happy                  9.3   8.4   10.2"
  },
  {
    "objectID": "project.html#reason-of-choice",
    "href": "project.html#reason-of-choice",
    "title": "Is Ignorance Truly Bliss*? Relationship between Education, Gender & Happiness",
    "section": "2.3 Reason of Choice",
    "text": "2.3 Reason of Choice\nEven in this century, the distinction between women and men is still evident in many areas in Turkey. Undoubtedly, educating individuals is the most effective way to change the position of women in society. And perhaps, in this way, a society that has educated itself reaches the most important value for a person: happiness."
  },
  {
    "objectID": "project.html#preprocessing",
    "href": "project.html#preprocessing",
    "title": "Is Ignorance Truly Bliss*? Relationship between Education, Gender & Happiness",
    "section": "2.4 Preprocessing",
    "text": "2.4 Preprocessing\nThe datasets used in this study will be merged to facilitate the analysis and will be organized in a way that allows easy processing by the program. If needed during the later stages of the analysis, additional datasets may be incorporated into the study. Different preprocessing steps have been applied to each dataset. The specific modifications made to each dataset are listed below in bullet points.\nPreprocessing for “education” dataset;\n\nThe presence of missing values (NA) is examined, and necessary preprocessing steps are applied if they exist.\nThe education levels (“Educational_Status”) in the “education” dataset (10 levels) were aligned with those in the ‘byeducation’ dataset (5 levels).\nIrrelevant information has been removed from the dataset to simplify it. For example, entries such as “Unknown” and “Total” in the “Educational_Status” column have been excluded.\n\n\n\nShow the code\n#changes in education dataset\n#head(education)\n#str(education)\n\n sum(is.na(education))\n\n\n[1] 0\n\n\nShow the code\n education&lt;- education |&gt; filter(!Educational_Status %in% c(\"Bilinmeyen\",\"Toplam\"))|&gt;\n  mutate(Educational_Status = case_when(\n    Educational_Status %in% c(\"Okuma yazma bilmeyen\", \"Okuma yazma bilen fakat bir okul bitirmeyen\") ~ \"No School Completed\",\n    Educational_Status== \"İlkokul\" ~ \"Primary School\",\n    Educational_Status %in% c(\"Ortaokul veya dengi meslek okulu\", \"İlköğretim\") ~ \"Primary Education or Junior High School\",\n    Educational_Status== \"Lise veya dengi meslek okulu\" ~ \"High School or Equivalent\",\n    Educational_Status %in% c(\"Yüksekokul veya fakülte\", \"Yüksek lisans ve üzeri\") ~ \"Higher Education\",\n    TRUE ~ as.character(Educational_Status))) \n  \n  education&lt;- education |&gt;  group_by(Year,Province,Educational_Status) |&gt;\n  summarise(\n    Total=sum(Total,na.rm = TRUE),\n    Male=sum(Male,na.rm = TRUE),\n    Female=sum(Female,na.rm = TRUE),\n    Percentage_Male=sum(Percentage_Male,na.rm = TRUE),\n    Percentage_Female=sum(Percentage_Female,na.rm = TRUE),\n    .groups = \"drop\"\n  )\n  \neducation$Educational_Status&lt;-factor(education$Educational_Status,levels= c(\"No School Completed\",\"Primary School\",\"Primary Education or Junior High School\",\"High School or Equivalent\",\"Higher Education\"),ordered = TRUE) \n\n\n\nhead(education)\n\n\n# A tibble: 6 × 8\n  Year  Province Educational_Status          Total   Male Female Percentage_Male\n  &lt;chr&gt; &lt;chr&gt;    &lt;ord&gt;                       &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;           &lt;dbl&gt;\n1 2008  ADANA    High School or Equivalent  300221 163672 136549            19.6\n2 2008  ADANA    Higher Education           100011  59440  40571             7.1\n3 2008  ADANA    No School Completed        552668 229450 323218            27.5\n4 2008  ADANA    Primary Education or Juni… 275436 150951 124485            18.1\n5 2008  ADANA    Primary School             469036 230288 238748            27.6\n6 2008  ADIYAMAN High School or Equivalent   62867  39780  23087            16.8\n# ℹ 1 more variable: Percentage_Female &lt;dbl&gt;\n\n\nThe variables and their corresponding value ranges in the finalized “education” dataset are defined as follows:\n\n\nShow the code\n str(education)\n\n\ntibble [6,480 × 8] (S3: tbl_df/tbl/data.frame)\n $ Year              : chr [1:6480] \"2008\" \"2008\" \"2008\" \"2008\" ...\n $ Province          : chr [1:6480] \"ADANA\" \"ADANA\" \"ADANA\" \"ADANA\" ...\n $ Educational_Status: Ord.factor w/ 5 levels \"No School Completed\"&lt;..: 4 5 1 3 2 4 5 1 3 2 ...\n $ Total             : num [1:6480] 300221 100011 552668 275436 469036 ...\n $ Male              : num [1:6480] 163672 59440 229450 150951 230288 ...\n $ Female            : num [1:6480] 136549 40571 323218 124485 238748 ...\n $ Percentage_Male   : num [1:6480] 19.6 7.1 27.5 18.1 27.6 16.8 4.4 35.5 20.1 23.3 ...\n $ Percentage_Female : num [1:6480] 15.8 4.7 37.5 14.4 27.6 9.5 1.8 52.4 15 21.5 ...\n\n\n\nYear: The year of the study (ranging from 2008 to 2023).\nProvince: Name of the province (81 provinces in total).\nEducational_Status: Education level (“No School Completed,” “Primary School,” “Primary Education or Junior High School,” “High School or Equivalent,” “Higher Education”).\nTotal: Total number of individuals in a given year, province, and education level.\nMale: Number of males in a given year, province, and education level.\nFemale: Number of females in a given year, province, and education level.\nPercentage_Male: Percentage of males in a given year, province, and education level.\nPercentage_Female: Percentage of females in a given year, province, and education level.\n\nDescriptive statistics for variables are presented below.\n\n\nShow the code\n summary(education)\n\n\n     Year             Province        \n Length:6480        Length:6480       \n Class :character   Class :character  \n Mode  :character   Mode  :character  \n                                      \n                                      \n                                      \n                               Educational_Status     Total         \n No School Completed                    :1296     Min.   :     681  \n Primary School                         :1296     1st Qu.:   42114  \n Primary Education or Junior High School:1296     Median :   86103  \n High School or Equivalent              :1296     Mean   :  190227  \n Higher Education                       :1296     3rd Qu.:  183118  \n                                                  Max.   :16154476  \n      Male             Female        Percentage_Male Percentage_Female\n Min.   :    257   Min.   :    424   Min.   : 0.00   Min.   : 0.00    \n 1st Qu.:  21807   1st Qu.:  19350   1st Qu.:12.70   1st Qu.:11.80    \n Median :  43320   Median :  41185   Median :19.80   Median :18.70    \n Mean   :  95128   Mean   :  95099   Mean   :19.45   Mean   :19.44    \n 3rd Qu.:  91336   3rd Qu.:  91346   3rd Qu.:25.82   3rd Qu.:25.80    \n Max.   :7930608   Max.   :8223868   Max.   :54.80   Max.   :79.50    \n\n\nPreprocessing for “byeducation” dataset;\n\nThe presence of missing values (NA) is examined, and necessary preprocessing steps are applied if they exist.\nThe “byeducation” dataset is updated to include data from 2008 to 2023, in accordance with the ‘education’ dataset, which contains information for the same years.\nThe variable “Happiness_Level”, which indicates the level of happiness, is defined as a factor variable with three levels.\n\n\n\nShow the code\n#changes in byeducation dataset\n#head(byeducation)\n#str(byeducation)\n\n\nsum(is.na(byeducation))\n\n\n[1] 0\n\n\nShow the code\nbyeducation&lt;- byeducation |&gt; filter(Year %in% 2008:2023)\nbyeducation$Happiness_Level&lt;-factor(byeducation$Happiness_Level,levels= c(\"Unhappy\",\"Neither happy nor unhappy\",\"Happy\"),ordered = TRUE) \n\n  \nhead(byeducation)\n\n\n# A tibble: 6 × 7\n   Year Happiness_Level           `No School Completed` `Primary  School`\n  &lt;dbl&gt; &lt;ord&gt;                                     &lt;dbl&gt;             &lt;dbl&gt;\n1  2008 Happy                                      55.8              54  \n2  2008 Neither happy nor unhappy                  26.3              31.8\n3  2008 Unhappy                                    17.8              14.2\n4  2009 Happy                                      51.8              52.5\n5  2009 Neither happy nor unhappy                  27.3              32.8\n6  2009 Unhappy                                    21                14.7\n# ℹ 3 more variables: `Primary Education or Junior High School` &lt;dbl&gt;,\n#   `High School or Equivalent` &lt;dbl&gt;, `Higher Education` &lt;dbl&gt;\n\n\nThe variables and their corresponding value ranges in the finalized “byeducation” dataset are defined as follows:\n\n\nShow the code\n str(byeducation)\n\n\ntibble [48 × 7] (S3: tbl_df/tbl/data.frame)\n $ Year                                   : num [1:48] 2008 2008 2008 2009 2009 ...\n $ Happiness_Level                        : Ord.factor w/ 3 levels \"Unhappy\"&lt;\"Neither happy nor unhappy\"&lt;..: 3 2 1 3 2 1 3 2 1 3 ...\n $ No School Completed                    : num [1:48] 55.8 26.3 17.8 51.8 27.3 21 56.3 28.9 14.8 57.2 ...\n $ Primary  School                        : num [1:48] 54 31.8 14.2 52.5 32.8 14.7 60.5 29 10.6 61.1 ...\n $ Primary Education or Junior High School: num [1:48] 55.3 31.7 12.9 56.1 32.3 11.6 61.6 27.6 10.8 64.4 ...\n $ High School or Equivalent              : num [1:48] 55.5 33.1 11.4 54.7 32.4 13 62.7 27.1 10.1 63.9 ...\n $ Higher Education                       : num [1:48] 62.9 24.6 12.5 63.2 27.8 9 67.7 26.2 6.1 66.7 ...\n\n\n\nYear: The study year (ranging from 2003 to 2008).\nHappiness_Level: Levels of happiness (“Unhappy,” “Neither Happy nor Unhappy,” “Happy”).\nNo School Completed: The percentage of individuals with no formal education for a given year and happiness level.\nPrimary School: The percentage of individuals who completed primary school for a given year and happiness level.\nPrimary Education or Junior High School: The percentage of individuals who completed primary education or junior high school for a given year and happiness level.\nHigh School or Equivalent: The percentage of individuals who completed high school or its equivalent for a given year and happiness level.\nHigher Education: The percentage of individuals who completed university or higher education for a given year and happiness level.\n\nDescriptive statistics for the variables are as follows:\n\n\nShow the code\n summary(byeducation)\n\n\n      Year                       Happiness_Level No School Completed\n Min.   :2008   Unhappy                  :16     Min.   :11.66      \n 1st Qu.:2012   Neither happy nor unhappy:16     1st Qu.:16.40      \n Median :2016   Happy                    :16     Median :28.20      \n Mean   :2016                                    Mean   :33.33      \n 3rd Qu.:2019                                    3rd Qu.:54.37      \n Max.   :2023                                    Max.   :63.54      \n Primary  School Primary Education or Junior High School\n Min.   :10.10   Min.   : 7.90                          \n 1st Qu.:14.18   1st Qu.:13.27                          \n Median :32.25   Median :32.47                          \n Mean   :33.34   Mean   :33.33                          \n 3rd Qu.:52.33   3rd Qu.:52.39                          \n Max.   :62.94   Max.   :64.40                          \n High School or Equivalent Higher Education\n Min.   : 8.10             Min.   : 6.10   \n 1st Qu.:13.36             1st Qu.:12.91   \n Median :33.03             Median :31.32   \n Mean   :33.33             Mean   :33.33   \n 3rd Qu.:50.88             3rd Qu.:51.57   \n Max.   :63.90             Max.   :67.70   \n\n\nPreprocessing for “bygender” dataset;\n\nThe presence of missing values (NA) is examined, and necessary preprocessing steps are applied if they exist.\nThe “bygender” dataset is updated to include data from 2008 to 2023, in accordance with the ‘education’ dataset, which contains information for the same years.\nHappiness levels in this dataset were originally assessed on five different levels. For the consistency of the analysis, the levels of happiness have been redefined and consolidated into three levels, similar to the categorization in the “bygender” dataset.\n\n\n\nShow the code\n#changes in bygender dataset\n#head(bygender)\n#str(bygender)\n\nsum(is.na(byeducation))\n\n\n[1] 0\n\n\nShow the code\nbygender &lt;- bygender |&gt; filter(Year %in% 2008:2023)|&gt;\n  mutate(Happiness_Level = case_when(\n    Happiness_Level %in% c(\"Very happy\", \"Happy\") ~ \"Happy\",\n    Happiness_Level %in% c(\"Very unhappy\", \"Unhappy\") ~ \"Unhappy\",\n    Happiness_Level== \"Neither happy nor unhappy\" ~ \"Neither happy nor unhappy\",\n    TRUE ~ as.character(Happiness_Level))) \n  \n  bygender&lt;- bygender |&gt; group_by(Year,Happiness_Level)|&gt; \n  summarise(\n    Total=sum(Total,na.rm = TRUE),\n    Male=sum(Male,na.rm = TRUE),\n    Female=sum(Female,na.rm = TRUE),\n    .groups = \"drop\"\n  )\n\nbygender$Happiness_Level&lt;-factor(bygender$Happiness_Level,levels= c(\"Unhappy\",\"Neither happy nor unhappy\",\"Happy\"),ordered = TRUE) \n\n  \nhead(bygender)\n\n\n# A tibble: 6 × 5\n   Year Happiness_Level           Total  Male Female\n  &lt;dbl&gt; &lt;ord&gt;                     &lt;dbl&gt; &lt;dbl&gt;  &lt;dbl&gt;\n1  2008 Happy                      55.7  53.7   57.8\n2  2008 Neither happy nor unhappy  30.3  30.7   30  \n3  2008 Unhappy                    13.9  15.7   12.2\n4  2009 Happy                      54.3  50.3   58.1\n5  2009 Neither happy nor unhappy  31.1  32.7   29.6\n6  2009 Unhappy                    14.6  17.1   12.3\n\n\nThe variables and their corresponding value ranges in the finalized “bygender” dataset are defined as follows:\n\n\nShow the code\n str(bygender)\n\n\ntibble [48 × 5] (S3: tbl_df/tbl/data.frame)\n $ Year           : num [1:48] 2008 2008 2008 2009 2009 ...\n $ Happiness_Level: Ord.factor w/ 3 levels \"Unhappy\"&lt;\"Neither happy nor unhappy\"&lt;..: 3 2 1 3 2 1 3 2 1 3 ...\n $ Total          : num [1:48] 55.7 30.3 13.9 54.3 31.1 14.6 61.2 28.1 10.8 62.1 ...\n $ Male           : num [1:48] 53.7 30.7 15.7 50.3 32.7 17.1 59.6 28.9 11.5 59.5 ...\n $ Female         : num [1:48] 57.8 30 12.2 58.1 29.6 12.3 62.7 27.3 10 64.6 ...\n\n\n\nYear: The study year (ranging from 2003 to 2008).\nHappiness_Level: Levels of happiness (“Unhappy,” “Neither Happy nor Unhappy,” “Happy”).\nTotal: The percentage of individuals for each year and happiness level.\nMale: The percentage of males for each year and happiness level.\nFemale: The percentage of females for each year and happiness level.\n\nDescriptive statistics for the variables are as follows:\n\n\nShow the code\n summary(bygender)\n\n\n      Year                       Happiness_Level     Total      \n Min.   :2008   Unhappy                  :16     Min.   : 9.90  \n 1st Qu.:2012   Neither happy nor unhappy:16     1st Qu.:14.35  \n Median :2016   Happy                    :16     Median :31.55  \n Mean   :2016                                    Mean   :33.33  \n 3rd Qu.:2019                                    3rd Qu.:52.40  \n Max.   :2023                                    Max.   :62.10  \n      Male           Female     \n Min.   :10.50   Min.   : 9.10  \n 1st Qu.:16.75   1st Qu.:12.18  \n Median :34.05   Median :29.70  \n Mean   :33.34   Mean   :33.34  \n 3rd Qu.:48.10   3rd Qu.:55.58  \n Max.   :59.60   Max.   :64.60"
  },
  {
    "objectID": "project.html#exploratory-data-analysis",
    "href": "project.html#exploratory-data-analysis",
    "title": "Is Ignorance Truly Bliss*? Relationship between Education, Gender & Happiness",
    "section": "3.1 Exploratory Data Analysis",
    "text": "3.1 Exploratory Data Analysis\nAt this stage of the analysis, visualizations will be used to explore the data in more detail, aiming to gain insights into the characteristics of different variables. To ensure a more structured analysis process, the datasets will be examined one by one in sequence. For each dataset, a set of questions will be explored with the aim of gaining deeper understanding and shedding light on key patterns.\nTo provide a more detailed analysis of the “education” dataset, the following questions will be examined.\nExamining the provinces and years with a high number of individuals holding higher education degrees or no formal education may offer meaningful insights into educational disparities. Question: Which are the top 10 provinces with the highest number of university graduates, and which are the top 10 provinces with the highest number of individuals who have not completed any formal education?\nBased on the graphs presented below, the following observations can be made:\n\nThe number of individuals with higher education has steadily increased over the years.\nThe provinces with the highest levels of higher education attainment remain relatively consistent over time, with major cities such as Istanbul, Ankara, and Izmir standing out.\nThis trend may be attributed to both the larger populations in these cities and the higher concentration of universities located there.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nBased on the graphs presented below, several observations can be made:\n\nOver the years, the number of individuals with no formal education has generally increased, reaching its peak in 2022 before starting to decline.\nThe provinces appearing in the top 10 list for individuals with no education often overlap with those that also rank high in higher education attainment. A major reason for this could be the concentration of Turkey’s population in these large metropolitan areas.\n\n\n\nShow the code\neducation |&gt; \n  filter(Educational_Status == \"No School Completed\") |&gt; \n  group_by(Year) |&gt; \n  slice_max(order_by = Total, n = 10) |&gt; \n  ungroup() |&gt; \n  ggplot(aes(x = reorder(Province, Total), y = Total/1000 ,width = 0.5)) +\n  geom_bar(stat = \"identity\", fill = \"darkgreen\") +\n  coord_flip() + \n  facet_wrap(~Year, scales = \"free_y\") +\n  labs(\n    title = \"Top 10 Provinces by No School Attainment (Each Year)\",\n    x = \"Province\",\n    y = \"Total (10³)\"\n  ) +\n  theme_minimal()+\n  theme(axis.text.x = element_text(angle = 90, hjust = 1, size = 6),axis.text.y= element_text(size=5.5))\n\n\n\n\n\n\n\n\n\nAfter examining the number of individuals with no formal education and those with higher education across provinces, the next step involves incorporating the gender dimension into the analysis. Question: What does the comparison between female and male proportions tell us about the presumed educational disadvantage faced by women?\nBelow, a series of maps illustrate the percentage of women and men with no formal education across provinces over time. The visualizations show that, in recent years, the number of men with no education has begun to surpass that of women in many provinces.\nDoes this observation indicate that the educational disadvantage has shifted over time to affect men more significantly?\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTo further investigate the findings from the map above, we can examine the gender distribution across different education levels (aggregated for all years at the national level) using the chart below.\nContrary to our earlier observation, the chart reveals that 57.48% of individuals with no formal education are women.\nSo, what do these seemingly conflicting results actually tell us?\nThey suggest that, overall, the number of women who have never received any formal education is significantly higher than that of men, even if recent trends indicate a growing number of uneducated men in certain regions.\n\n\nShow the code\n education |&gt; group_by(Educational_Status)  |&gt;\n  summarise(Male = sum(Male),\n            Female = sum(Female)) |&gt; mutate(Total = Male + Female,\n         Male = Male / Total * 100,\n         Female = Female / Total * 100) |&gt;\n  pivot_longer(cols = c(\"Male\", \"Female\"), names_to = \"Gender\", values_to = \"Percentage\") |&gt;\n  ggplot(aes(x = Educational_Status, y = Percentage, fill = Gender)) +\n  geom_bar(stat = \"identity\", position = \"dodge\") +\n  labs(title = \"Educational vs Gender (Country wise)\", x = \"Educational Status\", y = \"Percentage\")+geom_text_repel(aes(label =round(Percentage,2)), color = \"black\", size = 3.5)+\n  theme(axis.text.x = element_text(angle = 30, hjust = 1, size = 7))\n\n\n\n\n\n\n\n\n\nTo provide a more detailed analysis of the “byeducation” dataset, the following questions will be examined.\nTo closely examine this dataset, the first step is to explore the relationship between education levels and life satisfaction. Question: Which education level group reports higher life satisfaction, and which one reports the lowest?\nBased on the results obtained, the following observations can be made:\n\nWithin a given year, the distribution of education levels across happiness categories shows relatively similar proportions.\nIndividuals with higher education have the highest average life satisfaction “Happy”, whereas those with only primary school education report the lowest.\nAmong those who identify as “Unhappy,” the largest proportion consists of individuals with no formal education, while the smallest share belongs to those with higher education.\nIndividuals with a high school education or with primary/junior high school education tend to display similar patterns, showing closely aligned averages across the different happiness levels.\n\n\n\nShow the code\n byeducation |&gt;\n  select(everything()) |&gt;\n  pivot_longer(cols = c(\"No School Completed\",\"Primary  School\",\"Primary Education or Junior High School\",\"High School or Equivalent\",\"Higher Education\"), names_to = \"Education_Level\", values_to = \"Percentage\") |&gt;ggplot(aes(x = Happiness_Level, y = Percentage, color = Education_Level)) +\n  geom_boxplot() +\n  labs(title = \"Happy percentage vs Education Level\",\n       x = \"Happiness_Level\", y = \"Percentage (%)\", color = \"Education_Level\") +\n  theme_minimal()\n\n\n\n\n\n\n\n\n\nTo provide a more detailed analysis of the “bygender” dataset, the following questions will be examined.\nTo closely examine the dataset, the first step is to explore the relationship between education levels and happiness levels. Question: How does the percentage of happiness vary for each gender?\nBased on the results obtained, the following observations can be made:\n\nWithin a given year, the distribution of happiness levels across genders shows similar proportions for both men and women.\nWomen report the highest average life satisfaction “Happy”, while men tend to have the lowest average satisfaction.\nThe majority of individuals who identify as “Unhappy” are men.\nThere is a notable difference between the average happiness percentages for men and women, particularly at the “Happy” level.\n\n\n\nShow the code\n bygender |&gt; \n  select( everything()) |&gt;\n  pivot_longer(cols = c(\"Male\", \"Female\"), names_to = \"Gender\", values_to = \"Percentage\") |&gt;ggplot(aes(x = Happiness_Level, y = Percentage, color = Gender)) +\n  geom_boxplot()+\n  labs(title = \"Happy percentage vs Gender\",\n       x = \"Happiness_Level\", y = \"Percentage (%)\", color = \"Gender\") +\n  theme_minimal()"
  },
  {
    "objectID": "project.html#trend-analysis",
    "href": "project.html#trend-analysis",
    "title": "Is Ignorance Truly Bliss*? Relationship between Education, Gender & Happiness",
    "section": "3.2 Trend Analysis",
    "text": "3.2 Trend Analysis\nIn this section, the behavior of different variables within the datasets over time will be examined. As in previous sections, the datasets will be analyzed separately, and the time-dependent behavior of the variables will be explored by addressing various research questions.\nAnalysis for “education” dataset\nIn the previous sections, we examined the top 10 provinces with the highest number of university graduates over different years. As the next step in the analysis, we can investigate the provinces where the rate of university graduates has increased most rapidly. Question: In which provinces has the rate of university graduates increased most rapidly?\nBased on the chart below, the following observations can be made:\n\nConsistent with our earlier findings, provinces such as Istanbul and Ankara, which appeared in the previous analysis, are also among the provinces that have shown the fastest growth in the number of individuals with higher education. One possible explanation for this is the large population size of these cities.\nIstanbul, the province with the highest number of university graduates, has shown a steady increase between 2008 and 2023. Similarly, Izmir has also demonstrated consistent growth.\nA particularly noteworthy observation is the sharp upward trend in Ankara, especially after 2020, where the growth rate increased significantly. A similar observation can be made for Konya and Bursa, though the growth rate in these cities is somewhat slower. This rapid increase, particularly after 2020, may be attributed to the growth in the number of universities in these cities and the migration they have received in recent years.\n\n\n\nShow the code\nuniv_trend &lt;- education |&gt;\n  filter(Educational_Status == \"Higher Education\") |&gt;\n  mutate(Total = Male + Female)\n\nslope_by_province &lt;- univ_trend %&gt;%\n  group_by(Province) %&gt;%\n  summarise(slope = coef(lm(Total ~ Year))[2]) %&gt;%\n  arrange(desc(slope))\n\nhead(slope_by_province, 10)\n\n\n# A tibble: 10 × 2\n   Province    slope\n   &lt;chr&gt;       &lt;dbl&gt;\n 1 İSTANBUL  166314.\n 2 ANKARA     92572.\n 3 İZMİR      55971.\n 4 BURSA      29044.\n 5 KONYA      23179.\n 6 ADANA      23058.\n 7 KOCAELİ    22834.\n 8 ANTALYA    21437.\n 9 MERSİN     19919.\n10 ESKİŞEHİR  16730.\n\n\nShow the code\ntop_provinces &lt;- slope_by_province %&gt;%\n  slice_max(order_by = slope, n = 5) %&gt;%\n  pull(Province)\n\nuniv_trend %&gt;%\n  filter(Province %in% top_provinces) %&gt;%\n  ggplot(aes(x = Year, y = Total/1000, color = Province, group = Province)) +  \n  geom_smooth(method = \"loess\", se = FALSE, linewidth = 1.2) +\n  labs(title = \" Provinces which rate of university graduates increased most rapidly\",\n       x = \"Year\", y = \"Total Graduates (10³) \") +\n  theme_minimal()\n\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\n\n\n\n\n\n\n\nAnalysis for “bygender” dataset\nIn the next step of our analysis, we can consider how life satisfaction has evolved over time for both men and women, based on the previously explored relationship between gender and happiness levels. Question: How has life satisfaction changed over time for men and women?\nBased on the chart below and in line with our earlier findings, the following observations can be made:\n\nIt appears that women generally report higher levels of happiness than men, supporting the notion that men tend to be more unhappy than women.\nIn 2016, a decrease was observed in the percentage of individuals reporting high life satisfaction. This decline is mirrored by an increase in the percentage of individuals identifying as “unhappy” after 2016.\n\n\n\nShow the code\nbygender_long &lt;- bygender |&gt; \n  pivot_longer(cols = c(\"Male\", \"Female\"), \n               names_to = \"Gender\", \n               values_to = \"Percentage\")\nggplot(bygender_long, aes(x = Year, y = Percentage, color = Gender)) +\n  geom_line(size = 1.2) +\n  geom_point(linewidth = 2) +\n  facet_wrap(~ Happiness_Level) +\n  labs(title = \"Life Satisfaction Trends by Gender and Level\",\n       x = \"Year\", y = \"Percentage (%)\",\n       color = \"Gender\") +\n  theme_minimal()\n\n\nWarning: Using `size` aesthetic for lines was deprecated in ggplot2 3.4.0.\nℹ Please use `linewidth` instead.\n\n\nWarning in geom_point(linewidth = 2): Ignoring unknown parameters: `linewidth`\n\n\n\n\n\n\n\n\n\nWe can conclude that there is a significant difference between men and women in terms of happiness levels. This conclusion can be further developed by examining whether the difference between men and women persists annually. Question: Does the difference in life satisfaction between men and women persist annually?\nBased on the analysis below, the following observations can be made:\n\nNegative values indicate that women are generally happier than men.\nWhen examining the statistical significance of the difference (i.e., whether the difference in happiness between men and women shows a meaningful trend over time) through linear regression, the p-value = 0.046, which is less than 0.05, indicating that the difference is statistically significant. On average, the difference between men and women in happiness levels decreases by 0.24 points per year.\n\n\n\nShow the code\nmutlu_df &lt;- bygender |&gt; \n  filter(Happiness_Level == \"Happy\") |&gt; \n  pivot_longer(cols = c(Male, Female), \n               names_to = \"Gender\", \n               values_to = \"Percentage\")|&gt;  \n  pivot_wider(names_from = Gender, values_from = Percentage)|&gt;\n  mutate(Difference = Male - Female)  \n  \n  ggplot(mutlu_df, aes(x = Year, y = Difference)) +\n  geom_line(color = \"darkred\", size = 1.2) +\n  geom_point(size = 2, color = \"darkred\") +\n  geom_hline(yintercept = 0, linetype = \"dashed\") +\n  geom_smooth(method = \"lm\", se = TRUE, color = \"black\", linetype = \"dotted\") +\n  labs(title = \"Trend of Gender Difference in Happiness Over Time\",\n       subtitle = \"Black dotted line: linear trend\",\n       x = \"Year\", y = \"Happiness Difference (Male - Female)\") +\n  theme_minimal()\n\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\n\n\n\n\n\n\n\nShow the code\nmodel &lt;- lm(Difference ~ Year, data = mutlu_df)\nsummary(model)\n\n\n\nCall:\nlm(formula = Difference ~ Year, data = mutlu_df)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-2.6632 -1.7616  0.1562  1.2136  3.8206 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)  \n(Intercept) 480.7669   223.5764   2.150   0.0495 *\nYear         -0.2419     0.1109  -2.181   0.0468 *\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 2.045 on 14 degrees of freedom\nMultiple R-squared:  0.2536,    Adjusted R-squared:  0.2003 \nF-statistic: 4.756 on 1 and 14 DF,  p-value: 0.04675\n\n\nSimilarly, the difference in happiness levels between men and women at the “Unhappy” level has also been examined for statistical significance. According to the results, since p = 0.0268, which is less than 0.05, the difference is statistically significant. On average, the difference between men and women in the “Unhappy” category increases by 0.17 points per year.\n\n\nShow the code\nmutsuz_df &lt;- bygender |&gt; \n  filter(Happiness_Level == \"Unhappy\") |&gt; \n  pivot_longer(cols = c(Male, Female), \n               names_to = \"Gender\", \n               values_to = \"Percentage\")|&gt;  \n  pivot_wider(names_from = Gender, values_from = Percentage)|&gt;\n  mutate(Difference = Male - Female)  \n  \n  ggplot(mutsuz_df, aes(x = Year, y = Difference)) +\n  geom_line(color = \"darkred\", size = 1.2) +\n  geom_point(size = 2, color = \"darkred\") +\n  geom_hline(yintercept = 0, linetype = \"dashed\") +\n  geom_smooth(method = \"lm\", se = TRUE, color = \"black\", linetype = \"dotted\") +\n  labs(title = \"Trend of Gender Difference in Unhappiness Over Time\",\n       subtitle = \"Black dotted line: linear trend\",\n       x = \"Year\", y = \"Happiness Difference (Male - Female)\") +\n  theme_minimal()\n\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\n\n\n\n\n\n\n\nShow the code\nmodel &lt;- lm(Difference ~ Year, data = mutsuz_df)\nsummary(model)\n\n\n\nCall:\nlm(formula = Difference ~ Year, data = mutsuz_df)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-1.4704 -0.8468 -0.5268  0.6701  2.4760 \n\nCoefficients:\n              Estimate Std. Error t value Pr(&gt;|t|)  \n(Intercept) -345.70574  141.18345  -2.449   0.0281 *\nYear           0.17324    0.07005   2.473   0.0268 *\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 1.292 on 14 degrees of freedom\nMultiple R-squared:  0.304, Adjusted R-squared:  0.2543 \nF-statistic: 6.116 on 1 and 14 DF,  p-value: 0.02683\n\n\nAnalysis for “byeducation” dataset\nWe have previously gathered some insights regarding the relationship between education levels and happiness levels in the dataset. As the next step in this analysis, we can consider how life satisfaction has evolved over time for different education levels. Question: How has life satisfaction percentage changed over level of education? Question: How has life satisfaction percentage changed over level of education?\nBased on the analysis provided below, the following observations can be made:\n\nThe percentage of individuals who report being happy has decreased across all education levels over time.\nThe smallest decrease in happiness levels has been observed among individuals without any education, with an average decrease of just 0.0089, which is a very low rate.\nThe education level with the greatest decline in life satisfaction over time is among individuals with higher education. For this group, the happiness percentage has decreased by an average of 1.369 points per year.\n\n\n\nShow the code\nedu_happy &lt;- byeducation |&gt;\n  filter(Happiness_Level==\"Happy\")|&gt;pivot_longer(c(`No School Completed`,`Primary  School`,`Primary Education or Junior High School`,`High School or Equivalent`,`Higher Education`),\n               names_to  = \"Educational_Status\",\n               values_to = \"Percentage\") \n\nedu_happy$Educational_Status &lt;- factor(\n  edu_happy$Educational_Status,\n  levels = c(\"No School Completed\",\"Primary  School\",\"Primary Education or Junior High School\",\"High School or Equivalent\",\"Higher Education\",order=TRUE)\n)\nggplot(edu_happy, aes(x = Year, y = Percentage, color = Educational_Status)) +\n geom_point() +\n  geom_smooth(method = \"lm\", se = FALSE, size = 1.2) +\n  labs(title = \"Life satisfaction percentage changed over level of education\",\n       x = \"Year\", y = \"Happy (%)\") +\n  theme_light()\n\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\n\n\n\n\n\n\n\nShow the code\nedu_trends &lt;- edu_happy %&gt;%\n  group_by(Educational_Status) %&gt;%\n  do(tidy(lm(Percentage ~ Year, data = .))) %&gt;%\n  filter(term == \"Year\") %&gt;%\n  arrange(desc(estimate))\n\nedu_trends\n\n\n# A tibble: 5 × 6\n# Groups:   Educational_Status [5]\n  Educational_Status                  term  estimate std.error statistic p.value\n  &lt;fct&gt;                               &lt;chr&gt;    &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;   &lt;dbl&gt;\n1 No School Completed                 Year   -0.0883     0.189    -0.468 6.47e-1\n2 Primary  School                     Year   -0.397      0.195    -2.04  6.11e-2\n3 High School or Equivalent           Year   -0.832      0.213    -3.91  1.58e-3\n4 Primary Education or Junior High S… Year   -0.884      0.231    -3.82  1.86e-3\n5 Higher Education                    Year   -1.37       0.171    -7.99  1.38e-6\n\n\nThe same analysis has been conducted for the “Unhappy” happiness level, and the following results were found:\n\nThe percentage of individuals who identify as “Unhappy” has increased over time for all education levels, except for those without any education.\nFor individuals without any education, the percentage of those who identify as “Unhappy” has decreased over time, with an average decrease of 0.065 per year.\nThe education level with the largest increase in the percentage of individuals who identify as “Unhappy” over time is higher education. For this group, the percentage of those who report being “Unhappy” has increased by an average of 0.45 points per year.\n\n\n\nShow the code\nedu_unhappy &lt;- byeducation |&gt;\n  filter(Happiness_Level==\"Unhappy\")|&gt;pivot_longer(c(`No School Completed`,`Primary  School`,`Primary Education or Junior High School`,`High School or Equivalent`,`Higher Education`),\n               names_to  = \"Educational_Status\",\n               values_to = \"Percentage\") \n\nedu_unhappy$Educational_Status &lt;- factor(\n  edu_unhappy$Educational_Status,\n  levels = c(\"No School Completed\",\"Primary  School\",\"Primary Education or Junior High School\",\"High School or Equivalent\",\"Higher Education\",order=TRUE)\n)\nggplot(edu_unhappy, aes(x = Year, y = Percentage, color = Educational_Status)) +\n geom_point() +\n  geom_smooth(method = \"lm\", se = FALSE, size = 1.2) +\n  labs(title = \"Life satisfaction  percentage changed over level of education\",\n       x = \"Year\", y = \"Unhappy (%)\") +\n  theme_light()\n\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\n\n\n\n\n\n\n\nShow the code\nedu_trends &lt;- edu_unhappy %&gt;%\n  group_by(Educational_Status) %&gt;%\n  do(tidy(lm(Percentage ~ Year, data = .))) %&gt;%\n  filter(term == \"Year\") %&gt;%\n  arrange(desc(estimate))\n\nedu_trends\n\n\n# A tibble: 5 × 6\n# Groups:   Educational_Status [5]\n  Educational_Status                  term  estimate std.error statistic p.value\n  &lt;fct&gt;                               &lt;chr&gt;    &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;   &lt;dbl&gt;\n1 Higher Education                    Year    0.452     0.124      3.66  0.00257\n2 Primary Education or Junior High S… Year    0.373     0.129      2.90  0.0116 \n3 High School or Equivalent           Year    0.340     0.112      3.03  0.00894\n4 Primary  School                     Year    0.182     0.0967     1.89  0.0802 \n5 No School Completed                 Year   -0.0657    0.132     -0.498 0.626"
  },
  {
    "objectID": "project.html#model-fitting",
    "href": "project.html#model-fitting",
    "title": "Is Ignorance Truly Bliss*? Relationship between Education, Gender & Happiness",
    "section": "3.3 Model Fitting",
    "text": "3.3 Model Fitting\nIn this section, the primary objective of the research will be addressed by statistically examining the relationships between variables that influence individuals’ happiness levels, their interconnections, and their association with happiness levels in more detail. Based on the findings, predictive models for the future will be developed. This approach will be carried out, as in previous steps, by answering key questions.\n\nQuestion: Is there a significant difference between educational level and happiness level? (using the “byeducation” dataset)\n\nAccording to the Chi-square test, the p-value is 2.2e-16, which is less than 0.05. Therefore, it can be concluded that happiness levels are significantly associated with education level.\n\n\nShow the code\n#\ndf&lt;- byeducation |&gt; pivot_longer(c(`No School Completed`,`Primary  School`,`Primary Education or Junior High School`,`High School or Equivalent`,`Higher Education`),\n               names_to  = \"Educational_Status\",\n               values_to = \"Percentage\") |&gt;\n mutate(Estimated_Count = round(Percentage * 1000 / 100))\n \n\nsummary_table &lt;- df %&gt;%\n  group_by(Happiness_Level, Educational_Status) %&gt;%\n  summarise(Count = sum(Estimated_Count), .groups = \"drop\")\n\ncontingency_matrix &lt;- summary_table %&gt;%\n  pivot_wider(names_from = Happiness_Level, values_from = Count) %&gt;%\n  column_to_rownames(\"Educational_Status\") %&gt;%\n  as.matrix()\nchisq.test(contingency_matrix)\n\n\n\n    Pearson's Chi-squared test\n\ndata:  contingency_matrix\nX-squared = 277.05, df = 8, p-value &lt; 2.2e-16\n\n\n\nQuestion: Is there a significant difference between educational level and gender? (using the “bygender” dataset)\n\nAccording to the Chi-square test, the p-value is 2.2e-16, which is less than 0.05. Therefore, it can be concluded that happiness levels are significantly associated with gender.\n\n\nShow the code\n#\ndf1&lt;- bygender |&gt; pivot_longer(c(Male,Female),\n               names_to  = \"Gender\",\n               values_to = \"Percentage\") |&gt;\n mutate(Estimated_Count = round(Percentage * 1000 / 100))\n \n\nsummary_table &lt;- df1 %&gt;%\n  group_by(Happiness_Level, Gender) %&gt;%\n  summarise(Count = sum(Estimated_Count), .groups = \"drop\")\n\ncontingency_matrix1 &lt;- summary_table %&gt;%\n  pivot_wider(names_from = Happiness_Level, values_from = Count) %&gt;%\n  column_to_rownames(\"Gender\") %&gt;%\n  as.matrix()\nchisq.test(contingency_matrix1)\n\n\n\n    Pearson's Chi-squared test\n\ndata:  contingency_matrix1\nX-squared = 170.61, df = 2, p-value &lt; 2.2e-16\n\n\n\nIt has once again been observed that happiness level (Happy) is influenced by both education level and gender. In the next stage of the analysis, separate predictive models were developed to estimate happiness levels based on education and gender variables.\n\nEducation Level-Based Happiness Level Prediction Model;\nA predictive model for estimating the percentage of individuals who report being happy based on education level can be constructed in three different ways:\n\nModel 1 assumes that happiness is influenced solely by education level.\nModel 2 includes the effect of time (year) in addition to education level.\nModel 3 incorporates the interaction between education level and time.\n\nBased on the results, when comparing the Akaike Information Criterion (AIC) values of the models, Model 3 was found to have the lowest AIC, indicating the best fit to the data. This suggests that the interaction between education level and year should be included in the predictive model for estimating happiness levels.\nAccordingly, the final model should include the statistically significant education levels — Primary Education or Junior High School, High School, and Higher Education — as well as their interactions with the year variable. Since the “Education_Level” variable is categorical, a reference category is selected when constructing the model, which is typically the first level. In this case, the reference category is the “No School Completed” category. The “Intercept”(β₀) value in the model output represents the average happiness percentage for “No School Completed” category, while the Other coefficients represent the difference between the average happiness percentage of the relevant education level and that of the ‘No School Completed’ category\nThe adequacy of the model was validated by analyzing whether the residuals conform to a normal distribution with Q-Q Plot and Anderson-Darling Normality Test.\n\n\nShow the code\nhappy_df_byeducation  &lt;- byeducation|&gt;\n  pivot_longer(\n    cols = -c(Year, Happiness_Level),\n    names_to = \"Education_Level\",\n    values_to = \"Percentage\"\n  ) |&gt;\n  filter(Happiness_Level == \"Happy\")|&gt;\nmutate(Education_Level = factor(Education_Level, \n                                  levels = c(\"No School Completed\",\"Primary  School\",\"Primary Education or Junior High School\",\"High School or Equivalent\",\"Higher Education\",order=TRUE)\n))\n\nmodel1 &lt;- lm(Percentage ~ Education_Level, data = happy_df_byeducation)\nsummary(model1)\n\n\n\nCall:\nlm(formula = Percentage ~ Education_Level, data = happy_df_byeducation)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-11.789  -2.971   0.011   3.602   9.761 \n\nCoefficients:\n                                                       Estimate Std. Error\n(Intercept)                                              56.642      1.340\nEducation_LevelPrimary  School                           -1.233      1.895\nEducation_LevelPrimary Education or Junior High School   -1.565      1.895\nEducation_LevelHigh School or Equivalent                 -1.353      1.895\nEducation_LevelHigher Education                           1.296      1.895\n                                                       t value Pr(&gt;|t|)    \n(Intercept)                                             42.262   &lt;2e-16 ***\nEducation_LevelPrimary  School                          -0.650    0.517    \nEducation_LevelPrimary Education or Junior High School  -0.826    0.412    \nEducation_LevelHigh School or Equivalent                -0.714    0.477    \nEducation_LevelHigher Education                          0.684    0.496    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 5.361 on 75 degrees of freedom\nMultiple R-squared:  0.04162,   Adjusted R-squared:  -0.009497 \nF-statistic: 0.8142 on 4 and 75 DF,  p-value: 0.5201\n\n\nShow the code\nggplot(happy_df_byeducation, aes(x = Education_Level, y = Percentage)) +\n  geom_boxplot(fill = \"darkseagreen2\") +\n  labs(title = \"Happy Percentage vs. Education Level\",\n       x = \"Education Level\", y = \"Happy(%)\") +\n  theme_minimal()+\n  theme(axis.text.x = element_text(angle = 30, hjust = 1, size = 7))\n\n\n\n\n\n\n\n\n\nShow the code\nmodel2 &lt;- lm(Percentage ~ Education_Level + Year, data = happy_df_byeducation)\nsummary(model2)\n\n\n\nCall:\nlm(formula = Percentage ~ Education_Level + Year, data = happy_df_byeducation)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-9.4845 -2.4151  0.4029  2.6386  7.8886 \n\nCoefficients:\n                                                        Estimate Std. Error\n(Intercept)                                            1496.0883   203.9767\nEducation_LevelPrimary  School                           -1.2328     1.4753\nEducation_LevelPrimary Education or Junior High School   -1.5648     1.4753\nEducation_LevelHigh School or Equivalent                 -1.3533     1.4753\nEducation_LevelHigher Education                           1.2962     1.4753\nYear                                                     -0.7142     0.1012\n                                                       t value Pr(&gt;|t|)    \n(Intercept)                                              7.335 2.33e-10 ***\nEducation_LevelPrimary  School                          -0.836    0.406    \nEducation_LevelPrimary Education or Junior High School  -1.061    0.292    \nEducation_LevelHigh School or Equivalent                -0.917    0.362    \nEducation_LevelHigher Education                          0.879    0.382    \nYear                                                    -7.057 7.70e-10 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 4.173 on 74 degrees of freedom\nMultiple R-squared:  0.4271,    Adjusted R-squared:  0.3884 \nF-statistic: 11.04 on 5 and 74 DF,  p-value: 5.843e-08\n\n\nShow the code\nmodel3 &lt;- lm(Percentage ~ Education_Level * Year, data = happy_df_byeducation)\nsummary(model3)\n\n\n\nCall:\nlm(formula = Percentage ~ Education_Level * Year, data = happy_df_byeducation)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-6.9436 -2.1574  0.0044  2.6583  7.7300 \n\nCoefficients:\n                                                              Estimate\n(Intercept)                                                  234.57621\nEducation_LevelPrimary  School                               620.91983\nEducation_LevelPrimary Education or Junior High School      1602.28219\nEducation_LevelHigh School or Equivalent                    1498.40007\nEducation_LevelHigher Education                             2583.10352\nYear                                                          -0.08828\nEducation_LevelPrimary  School:Year                           -0.30868\nEducation_LevelPrimary Education or Junior High School:Year   -0.79576\nEducation_LevelHigh School or Equivalent:Year                 -0.74411\nEducation_LevelHigher Education:Year                          -1.28098\n                                                            Std. Error t value\n(Intercept)                                                  404.91157   0.579\nEducation_LevelPrimary  School                               572.63143   1.084\nEducation_LevelPrimary Education or Junior High School       572.63143   2.798\nEducation_LevelHigh School or Equivalent                     572.63143   2.617\nEducation_LevelHigher Education                              572.63143   4.511\nYear                                                           0.20090  -0.439\nEducation_LevelPrimary  School:Year                            0.28411  -1.086\nEducation_LevelPrimary Education or Junior High School:Year    0.28411  -2.801\nEducation_LevelHigh School or Equivalent:Year                  0.28411  -2.619\nEducation_LevelHigher Education:Year                           0.28411  -4.509\n                                                            Pr(&gt;|t|)    \n(Intercept)                                                  0.56423    \nEducation_LevelPrimary  School                               0.28194    \nEducation_LevelPrimary Education or Junior High School       0.00663 ** \nEducation_LevelHigh School or Equivalent                     0.01087 *  \nEducation_LevelHigher Education                             2.53e-05 ***\nYear                                                         0.66170    \nEducation_LevelPrimary  School:Year                          0.28099    \nEducation_LevelPrimary Education or Junior High School:Year  0.00658 ** \nEducation_LevelHigh School or Equivalent:Year                0.01080 *  \nEducation_LevelHigher Education:Year                        2.56e-05 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 3.704 on 70 degrees of freedom\nMultiple R-squared:  0.5729,    Adjusted R-squared:  0.518 \nF-statistic: 10.43 on 9 and 70 DF,  p-value: 4.852e-10\n\n\nShow the code\nAIC(model1, model2, model3)\n\n\n       df      AIC\nmodel1  6 502.5322\nmodel2  7 463.3631\nmodel3 11 447.8703\n\n\nShow the code\nggplot(happy_df_byeducation, aes(sample = resid(model3))) +\n  stat_qq() +\n  stat_qq_line(color = \"darkgreen\") +\n  labs(title = \"Normal Q-Q Plot\") +\n  theme_clean()\n\n\n\n\n\n\n\n\n\nShow the code\nresiduals &lt;- resid(model3)\n\nad_test_results &lt;- ad.test(residuals)\nprint(ad_test_results)\n\n\n\n    Anderson-Darling normality test\n\ndata:  residuals\nA = 0.31572, p-value = 0.5353\n\n\nGender-Based Happiness Level Prediction Model;\nThe prediction model for happiness percentages based on gender can be established in three different ways.\n\nModel 1 assumes that the happiness rate is only affected by gender.\nModel 2 includes the effect of time in the prediction model.\nModel 3 adds the interaction between gender and time to the prediction model.\n\nBased on the results, when the AIC (Akaike Information Criterion) values of the models are compared, it is observed that the model that best explains the data is Model 2, which has the lowest AIC value. Therefore, it can be concluded that the effect of the year should be included in the constructed prediction model.\nThus, in the prediction model for happiness percentage, the significant variables, “GenderFemale” (which takes a value of 0 for Male and 1 for Female) and “Year”, should be included. Since the “Gender” variable is categorical, a reference category is selected when constructing the model, which is typically the first level. In this case, the reference category is the “Male” category. The “Intercept”(β₀) value in the model output represents the average happiness percentage for males, while the “GenderFemale” coefficient indicates the difference in the average happiness percentage between females and males.\nThe adequacy of the model was validated by analyzing whether the residuals conform to a normal distribution with Q-Q Plot and Anderson-Darling Normality Test.\n\n\nShow the code\nhappy_df_bygender  &lt;- bygender|&gt;\n  pivot_longer(cols = c(\"Male\", \"Female\"), \n               names_to = \"Gender\", \n               values_to = \"Percentage\")|&gt;\n  filter(Happiness_Level == \"Happy\")|&gt;\nmutate(Gender = factor(Gender,levels = c(\"Male\",\"Female\")\n))\n\nmodel1 &lt;- lm(Percentage ~ Gender, data = happy_df_bygender)\nsummary(model1)\n\n\n\nCall:\nlm(formula = Percentage ~ Gender, data = happy_df_bygender)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-8.9562 -2.9828  0.1938  3.6625  7.3438 \n\nCoefficients:\n             Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)    52.256      1.171  44.619  &lt; 2e-16 ***\nGenderFemale    6.806      1.656   4.109 0.000283 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 4.685 on 30 degrees of freedom\nMultiple R-squared:  0.3602,    Adjusted R-squared:  0.3388 \nF-statistic: 16.89 on 1 and 30 DF,  p-value: 0.0002825\n\n\nShow the code\nggplot(happy_df_bygender, aes(x = Gender, y = Percentage)) +\n  geom_boxplot(fill = \"darkseagreen2\") +\n  labs(title = \"Happy Percentage vs. Gender\",\n       x = \"Gender\", y = \"Happy (%)\") +\n  theme_minimal()\n\n\n\n\n\n\n\n\n\nShow the code\nmodel2 &lt;- lm(Percentage ~ Gender+ Year, data = happy_df_bygender)\nsummary(model2)\n\n\n\nCall:\nlm(formula = Percentage ~ Gender + Year, data = happy_df_bygender)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-6.1588 -2.2183  0.2604  2.3922  6.1670 \n\nCoefficients:\n              Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)  1355.3659   277.6201   4.882 3.52e-05 ***\nGenderFemale    6.8063     1.2699   5.360 9.34e-06 ***\nYear           -0.6465     0.1377  -4.694 5.94e-05 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 3.592 on 29 degrees of freedom\nMultiple R-squared:  0.6364,    Adjusted R-squared:  0.6113 \nF-statistic: 25.38 on 2 and 29 DF,  p-value: 4.256e-07\n\n\nShow the code\nmodel3 &lt;- lm(Percentage ~ Gender * Year, data = happy_df_bygender)\nsummary(model3)\n\n\n\nCall:\nlm(formula = Percentage ~ Gender * Year, data = happy_df_bygender)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-6.9450 -2.2140  0.1197  2.6519  6.2275 \n\nCoefficients:\n                   Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)       1599.1525   394.2144   4.057 0.000361 ***\nGenderFemale      -480.7669   557.5034  -0.862 0.395817    \nYear                -0.7675     0.1956  -3.924 0.000515 ***\nGenderFemale:Year    0.2419     0.2766   0.875 0.389249    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 3.607 on 28 degrees of freedom\nMultiple R-squared:  0.6461,    Adjusted R-squared:  0.6081 \nF-statistic: 17.04 on 3 and 28 DF,  p-value: 1.716e-06\n\n\nShow the code\nAIC(model1, model2, model3)\n\n\n       df      AIC\nmodel1  3 193.5824\nmodel2  4 177.4970\nmodel3  5 178.6346\n\n\nShow the code\nggplot(happy_df_bygender, aes(sample = resid(model2))) +\n  stat_qq() +\n  stat_qq_line(color = \"darkgreen\") +\n  labs(title = \"Normal Q-Q Plot\") +\n  theme_clean()\n\n\n\n\n\n\n\n\n\nShow the code\nresiduals &lt;- resid(model2)\n\nad_test_results &lt;- ad.test(residuals)\nprint(ad_test_results)\n\n\n\n    Anderson-Darling normality test\n\ndata:  residuals\nA = 0.22885, p-value = 0.793"
  },
  {
    "objectID": "project.html#results",
    "href": "project.html#results",
    "title": "Is Ignorance Truly Bliss*? Relationship between Education, Gender & Happiness",
    "section": "3.4 Results",
    "text": "3.4 Results\nxxxxxx"
  },
  {
    "objectID": "assignments.html",
    "href": "assignments.html",
    "title": "My Assignments",
    "section": "",
    "text": "On this page, I showcase the assignment I conducted for the [ Spring 2024-2025] EMU660 Decision Making with Analytics course.\nPlease use left menu to navigate through my assignments.\n\n\n\n Back to top",
    "crumbs": [
      "My Assignments"
    ]
  },
  {
    "objectID": "about.html#employements",
    "href": "about.html#employements",
    "title": "About Me",
    "section": "Employements",
    "text": "Employements\n\nLUPE Consulting, SAP Consultant , 2020-2021"
  },
  {
    "objectID": "about.html#internships",
    "href": "about.html#internships",
    "title": "About Me",
    "section": "Internships",
    "text": "Internships\n\nFNSS Defense Systems, Intern, 2017\nTurkish Aerospace Industries, Intern 2018"
  },
  {
    "objectID": "posts.html",
    "href": "posts.html",
    "title": "My Blog",
    "section": "",
    "text": "This page is under construction.\n\n\n\n Back to top"
  },
  {
    "objectID": "docs/assignments/assignment-1.html",
    "href": "docs/assignments/assignment-1.html",
    "title": "Assignment 1",
    "section": "",
    "text": "1 + 1\n\n[1] 2\n\n\nMy first assignment has two parts."
  },
  {
    "objectID": "assignments/assignment-1.html",
    "href": "assignments/assignment-1.html",
    "title": "Assignment 1",
    "section": "",
    "text": "My first assignment has three parts.",
    "crumbs": [
      "Assignment 1"
    ]
  },
  {
    "objectID": "assignments/assignment-2.html",
    "href": "assignments/assignment-2.html",
    "title": "Assignment 2",
    "section": "",
    "text": "Assignment 2\n\n1 + 1\n\n[1] 2\n\n\n\n\n\n\n Back to top",
    "crumbs": [
      "Assignment 2"
    ]
  },
  {
    "objectID": "assignments/assignment-1.html#a",
    "href": "assignments/assignment-1.html#a",
    "title": "Assignment 1",
    "section": "(a)",
    "text": "(a)\nA brief summary for Mr. Demirtas` speech;\nMr.Demirtas, in his talk, first briefly introduced himself, his background, and his research areas (Replenishment allocation problems, simulation, autonomous vehicles), as well as his work at Invent.ai. The talk can be divided into two parts. In the first part, the definition of data science was given, and its stages were enriched with examples. In the second part, Mr. Demirtas briefly discussed his doctoral thesis and then answered questions about artificial intelligence and data science.\nData science does not always provide exact answers. The key is to ask the right questions, compare the results with the real world, and update models to analyze data correctly. Artificial intelligence and machine learning are tools within data science, but data science is a broader field. Additionally, algorithms and modeling approaches can vary significantly depending on the problem. Data science uses models, algorithms, and analytical techniques to extract meaningful insights from data. Although it has become one of the most popular professions in recent years, artificial intelligence cannot replace data science because the human factor, interpretation, and decision-making processes play a critical role.\nThe data science process consists of problem definition, data collection, exploratory data analysis (EDA), modeling, evaluation, and analyzing results. Problem definition ensures a proper start. For example, Abraham Wald’s analysis of the reasons for the bombing aircraft crashes during World War II illustrates this step. Data can be collected from sources such as sensors and databases. The collected data can be structured or unstructured. Without quality data, it is difficult to obtain accurate results. In the exploratory data analysis (EDA) phase, visualization is an essential tool for understanding the data. For instance, in 1854, Dr. John Snow proved that cholera in London spread through water, not air, by analyzing data.\nIn the model building phase, mathematical models and algorithms are used to derive insights from the data, make predictions, and generate solutions. The fundamental techniques include descriptive (descriptive), predictive (predictive), and prescriptive (prescriptive) analysis. For instance, the weather prediction model developed by Lewis Fry Richardson in 1932 attempted to solve a long-standing problem with the limited tools of that time. Today, however, such problems can be solved in much less time, highlighting the progress of technology and the potential solutions that may emerge in the future. Another example is the mathematical model developed during World War II to ensure sufficient nutrition for soldiers. During the evaluation phase of the model, its success is tested, and issues such as overfitting (when the model memorizes training data too closely) or underfitting (when the model is too simplistic) are analyzed. For example, IBM’s Deep Blue computer tried to win against chess champion Garry Kasparov by memorizing all his moves. However, Kasparov’s unexpected moves revealed the model’s limited learning structure. Finally, during the Deployment & Live Performance stage, the model is integrated into real-world applications, and its performance is monitored. It is important for systems dealing with big data to manage real-time errors and to be scalable.\nAt the end of his talk, Mr. Demirtas discussed his doctoral research, which uses the Cellular Automaton Model to explore how autonomous vehicles can reduce traffic congestion. The goal is to minimize traffic buildup caused by stop-and-go driving or lane changes. The core objective of the thesis is to control when autonomous vehicles should merge, separate, and adjust their speed to optimize traffic flow. By properly guiding autonomous vehicles, maximum efficiency in traffic can be achieved.",
    "crumbs": [
      "Assignment 1"
    ]
  },
  {
    "objectID": "assignments/assignment-1.html#b",
    "href": "assignments/assignment-1.html#b",
    "title": "Assignment 1",
    "section": "(b)",
    "text": "(b)\nExploring Statistical Summaries with Custom Functions and Iteration Methods;\n\n\n[1] \"Summary for given data; \"\n[1] \"mpg\"\n$Min.\n[1] 10.4\n\n$`1st Qu.`\n[1] 15.425\n\n$Median\n[1] 19.2\n\n$`3rd Qu.`\n[1] 22.8\n\n$Max.\n[1] 33.9\n\n$Mean.\n[1] 20.09062\n\n$Var.\n[1] 36.3241\n\n[1] \"Summary for given data; \"\n[1] \"cyl\"\n$Min.\n[1] 4\n\n$`1st Qu.`\n[1] 4\n\n$Median\n[1] 6\n\n$`3rd Qu.`\n[1] 8\n\n$Max.\n[1] 8\n\n$Mean.\n[1] 6.1875\n\n$Var.\n[1] 3.189516\n\n[1] \"Summary for given data; \"\n[1] \"disp\"\n$Min.\n[1] 71.1\n\n$`1st Qu.`\n[1] 120.825\n\n$Median\n[1] 196.3\n\n$`3rd Qu.`\n[1] 326\n\n$Max.\n[1] 472\n\n$Mean.\n[1] 230.7219\n\n$Var.\n[1] 15360.8\n\n[1] \"Summary for given data; \"\n[1] \"hp\"\n$Min.\n[1] 52\n\n$`1st Qu.`\n[1] 96.5\n\n$Median\n[1] 123\n\n$`3rd Qu.`\n[1] 180\n\n$Max.\n[1] 335\n\n$Mean.\n[1] 146.6875\n\n$Var.\n[1] 4700.867\n\n[1] \"Summary for given data; \"\n[1] \"drat\"\n$Min.\n[1] 2.76\n\n$`1st Qu.`\n[1] 3.08\n\n$Median\n[1] 3.695\n\n$`3rd Qu.`\n[1] 3.92\n\n$Max.\n[1] 4.93\n\n$Mean.\n[1] 3.596563\n\n$Var.\n[1] 0.2858814\n\n[1] \"Summary for given data; \"\n[1] \"wt\"\n$Min.\n[1] 1.513\n\n$`1st Qu.`\n[1] 2.58125\n\n$Median\n[1] 3.325\n\n$`3rd Qu.`\n[1] 3.61\n\n$Max.\n[1] 5.424\n\n$Mean.\n[1] 3.21725\n\n$Var.\n[1] 0.957379\n\n[1] \"Summary for given data; \"\n[1] \"qsec\"\n$Min.\n[1] 14.5\n\n$`1st Qu.`\n[1] 16.8925\n\n$Median\n[1] 17.71\n\n$`3rd Qu.`\n[1] 18.9\n\n$Max.\n[1] 22.9\n\n$Mean.\n[1] 17.84875\n\n$Var.\n[1] 3.193166\n\n[1] \"Summary for given data; \"\n[1] \"vs\"\n$Min.\n[1] 0\n\n$`1st Qu.`\n[1] 0\n\n$Median\n[1] 0\n\n$`3rd Qu.`\n[1] 1\n\n$Max.\n[1] 1\n\n$Mean.\n[1] 0.4375\n\n$Var.\n[1] 0.2540323\n\n[1] \"Summary for given data; \"\n[1] \"am\"\n$Min.\n[1] 0\n\n$`1st Qu.`\n[1] 0\n\n$Median\n[1] 0\n\n$`3rd Qu.`\n[1] 1\n\n$Max.\n[1] 1\n\n$Mean.\n[1] 0.40625\n\n$Var.\n[1] 0.2489919\n\n[1] \"Summary for given data; \"\n[1] \"gear\"\n$Min.\n[1] 3\n\n$`1st Qu.`\n[1] 3\n\n$Median\n[1] 4\n\n$`3rd Qu.`\n[1] 4\n\n$Max.\n[1] 5\n\n$Mean.\n[1] 3.6875\n\n$Var.\n[1] 0.5443548\n\n[1] \"Summary for given data; \"\n[1] \"carb\"\n$Min.\n[1] 1\n\n$`1st Qu.`\n[1] 2\n\n$Median\n[1] 2\n\n$`3rd Qu.`\n[1] 4\n\n$Max.\n[1] 8\n\n$Mean.\n[1] 2.8125\n\n$Var.\n[1] 2.608871\n\n\n\n\n$Min.\n[1] 10.4\n\n$`1st Qu.`\n[1] 15.425\n\n$Median\n[1] 19.2\n\n$`3rd Qu.`\n[1] 22.8\n\n$Max.\n[1] 33.9\n\n$Mean.\n[1] 20.09062\n\n$Var.\n[1] 36.3241\n\n$Min.\n[1] 4\n\n$`1st Qu.`\n[1] 4\n\n$Median\n[1] 6\n\n$`3rd Qu.`\n[1] 8\n\n$Max.\n[1] 8\n\n$Mean.\n[1] 6.1875\n\n$Var.\n[1] 3.189516\n\n$Min.\n[1] 71.1\n\n$`1st Qu.`\n[1] 120.825\n\n$Median\n[1] 196.3\n\n$`3rd Qu.`\n[1] 326\n\n$Max.\n[1] 472\n\n$Mean.\n[1] 230.7219\n\n$Var.\n[1] 15360.8\n\n$Min.\n[1] 52\n\n$`1st Qu.`\n[1] 96.5\n\n$Median\n[1] 123\n\n$`3rd Qu.`\n[1] 180\n\n$Max.\n[1] 335\n\n$Mean.\n[1] 146.6875\n\n$Var.\n[1] 4700.867\n\n$Min.\n[1] 2.76\n\n$`1st Qu.`\n[1] 3.08\n\n$Median\n[1] 3.695\n\n$`3rd Qu.`\n[1] 3.92\n\n$Max.\n[1] 4.93\n\n$Mean.\n[1] 3.596563\n\n$Var.\n[1] 0.2858814\n\n$Min.\n[1] 1.513\n\n$`1st Qu.`\n[1] 2.58125\n\n$Median\n[1] 3.325\n\n$`3rd Qu.`\n[1] 3.61\n\n$Max.\n[1] 5.424\n\n$Mean.\n[1] 3.21725\n\n$Var.\n[1] 0.957379\n\n$Min.\n[1] 14.5\n\n$`1st Qu.`\n[1] 16.8925\n\n$Median\n[1] 17.71\n\n$`3rd Qu.`\n[1] 18.9\n\n$Max.\n[1] 22.9\n\n$Mean.\n[1] 17.84875\n\n$Var.\n[1] 3.193166\n\n$Min.\n[1] 0\n\n$`1st Qu.`\n[1] 0\n\n$Median\n[1] 0\n\n$`3rd Qu.`\n[1] 1\n\n$Max.\n[1] 1\n\n$Mean.\n[1] 0.4375\n\n$Var.\n[1] 0.2540323\n\n$Min.\n[1] 0\n\n$`1st Qu.`\n[1] 0\n\n$Median\n[1] 0\n\n$`3rd Qu.`\n[1] 1\n\n$Max.\n[1] 1\n\n$Mean.\n[1] 0.40625\n\n$Var.\n[1] 0.2489919\n\n$Min.\n[1] 3\n\n$`1st Qu.`\n[1] 3\n\n$Median\n[1] 4\n\n$`3rd Qu.`\n[1] 4\n\n$Max.\n[1] 5\n\n$Mean.\n[1] 3.6875\n\n$Var.\n[1] 0.5443548\n\n$Min.\n[1] 1\n\n$`1st Qu.`\n[1] 2\n\n$Median\n[1] 2\n\n$`3rd Qu.`\n[1] 4\n\n$Max.\n[1] 8\n\n$Mean.\n[1] 2.8125\n\n$Var.\n[1] 2.608871\n\n\n$mpg\n$mpg$Min.\n[1] 10.4\n\n$mpg$`1st Qu.`\n[1] 15.425\n\n$mpg$Median\n[1] 19.2\n\n$mpg$`3rd Qu.`\n[1] 22.8\n\n$mpg$Max.\n[1] 33.9\n\n$mpg$Mean.\n[1] 20.09062\n\n$mpg$Var.\n[1] 36.3241\n\n\n$cyl\n$cyl$Min.\n[1] 4\n\n$cyl$`1st Qu.`\n[1] 4\n\n$cyl$Median\n[1] 6\n\n$cyl$`3rd Qu.`\n[1] 8\n\n$cyl$Max.\n[1] 8\n\n$cyl$Mean.\n[1] 6.1875\n\n$cyl$Var.\n[1] 3.189516\n\n\n$disp\n$disp$Min.\n[1] 71.1\n\n$disp$`1st Qu.`\n[1] 120.825\n\n$disp$Median\n[1] 196.3\n\n$disp$`3rd Qu.`\n[1] 326\n\n$disp$Max.\n[1] 472\n\n$disp$Mean.\n[1] 230.7219\n\n$disp$Var.\n[1] 15360.8\n\n\n$hp\n$hp$Min.\n[1] 52\n\n$hp$`1st Qu.`\n[1] 96.5\n\n$hp$Median\n[1] 123\n\n$hp$`3rd Qu.`\n[1] 180\n\n$hp$Max.\n[1] 335\n\n$hp$Mean.\n[1] 146.6875\n\n$hp$Var.\n[1] 4700.867\n\n\n$drat\n$drat$Min.\n[1] 2.76\n\n$drat$`1st Qu.`\n[1] 3.08\n\n$drat$Median\n[1] 3.695\n\n$drat$`3rd Qu.`\n[1] 3.92\n\n$drat$Max.\n[1] 4.93\n\n$drat$Mean.\n[1] 3.596563\n\n$drat$Var.\n[1] 0.2858814\n\n\n$wt\n$wt$Min.\n[1] 1.513\n\n$wt$`1st Qu.`\n[1] 2.58125\n\n$wt$Median\n[1] 3.325\n\n$wt$`3rd Qu.`\n[1] 3.61\n\n$wt$Max.\n[1] 5.424\n\n$wt$Mean.\n[1] 3.21725\n\n$wt$Var.\n[1] 0.957379\n\n\n$qsec\n$qsec$Min.\n[1] 14.5\n\n$qsec$`1st Qu.`\n[1] 16.8925\n\n$qsec$Median\n[1] 17.71\n\n$qsec$`3rd Qu.`\n[1] 18.9\n\n$qsec$Max.\n[1] 22.9\n\n$qsec$Mean.\n[1] 17.84875\n\n$qsec$Var.\n[1] 3.193166\n\n\n$vs\n$vs$Min.\n[1] 0\n\n$vs$`1st Qu.`\n[1] 0\n\n$vs$Median\n[1] 0\n\n$vs$`3rd Qu.`\n[1] 1\n\n$vs$Max.\n[1] 1\n\n$vs$Mean.\n[1] 0.4375\n\n$vs$Var.\n[1] 0.2540323\n\n\n$am\n$am$Min.\n[1] 0\n\n$am$`1st Qu.`\n[1] 0\n\n$am$Median\n[1] 0\n\n$am$`3rd Qu.`\n[1] 1\n\n$am$Max.\n[1] 1\n\n$am$Mean.\n[1] 0.40625\n\n$am$Var.\n[1] 0.2489919\n\n\n$gear\n$gear$Min.\n[1] 3\n\n$gear$`1st Qu.`\n[1] 3\n\n$gear$Median\n[1] 4\n\n$gear$`3rd Qu.`\n[1] 4\n\n$gear$Max.\n[1] 5\n\n$gear$Mean.\n[1] 3.6875\n\n$gear$Var.\n[1] 0.5443548\n\n\n$carb\n$carb$Min.\n[1] 1\n\n$carb$`1st Qu.`\n[1] 2\n\n$carb$Median\n[1] 2\n\n$carb$`3rd Qu.`\n[1] 4\n\n$carb$Max.\n[1] 8\n\n$carb$Mean.\n[1] 2.8125\n\n$carb$Var.\n[1] 2.608871",
    "crumbs": [
      "Assignment 1"
    ]
  },
  {
    "objectID": "assignments/assignment-1.html#c",
    "href": "assignments/assignment-1.html#c",
    "title": "Assignment 1",
    "section": "(c)",
    "text": "(c)\nNA (missing) values\n\n\n[1] 12\n[1] 17\n[1] 27\n[1] 50\n[1] 51\n[1] 52\n[1] 59\n[1] 65\n[1] 66\n[1] 68\n[1] 91\n[1] 117\n[1] 125\n[1] 126\n[1] 127\n[1] 128\n[1] 139\n[1] 140\n[1] 141\n[1] 142\n[1] 153\n[1] 158\n[1] 168\n[1] 169\n[1] 172\n[1] 179\n[1] 189\n[1] 190\n[1] 203\n[1] 205\n[1] 207\n[1] 208\n[1] 212\n[1] 214\n[1] 237\n[1] 241\n[1] 243\n[1] 244\n[1] 253\n[1] 257\n[1] 265\n[1] 267\n[1] 269\n[1] 279\n[1] 282\n[1] 287\n[1] 290\n[1] 298\n[1] 310\n[1] 325\n[1] 326\n[1] 330\n[1] 341\n[1] 348\n[1] 361\n[1] 374\n[1] 392\n[1] 395\n[1] 397\n[1] 407\n[1] 410\n[1] 437\n[1] 443\n[1] 446\n[1] 461\n[1] 468\n[1] 470\n[1] 490\n[1] 496\n[1] 505\n[1] 527\n[1] 536\n[1] 539\n[1] 553\n[1] 561\n[1] 576\n[1] 578\n[1] 589\n[1] 599\n[1] 603\n[1] 609\n[1] 616\n[1] 618\n[1] 620\n[1] 630\n[1] 633\n[1] 636\n[1] 641\n[1] 652\n[1] 653\n[1] 666\n[1] 667\n[1] 668\n[1] 677\n[1] 680\n[1] 687\n[1] 691\n[1] 695\n[1] 701\n[1] 726\n[1] 734\n[1] 735\n[1] 736\n[1] 745\n[1] 746\n[1] 747\n[1] 748\n[1] 751\n[1] 756\n[1] 762\n[1] 767\n[1] 788\n[1] 789\n[1] 807\n[1] 821\n[1] 826\n[1] 832\n[1] 838\n[1] 843\n[1] 844\n[1] 845\n[1] 849\n[1] 850\n[1] 853\n[1] 859\n[1] 869\n[1] 887\n[1] 892\n[1] 893\n[1] 906\n[1] 909\n[1] 911\n[1] 918\n[1] 924\n[1] 925\n[1] 939\n[1] 943\n[1] 950\n[1] 962\n[1] 965\n[1] 966\n[1] 968\n[1] 979\n[1] 990\n[1] 999\n\n\n[1] TRUE\n\n\n[1] \"Mean and St.Dev. of original data set\"\n\n\n[1] 2.301754\n\n\n[1] 1.22338\n\n\n[1] \"Mean and St.Dev. of Version 1 data set\"\n\n\n[1] 2.258\n\n\n[1] 1.136102\n\n\n[1] \"Mean and St.Dev. of Version 2 data set\"\n\n\n[1] 2.403\n\n\n[1] 1.157554\n\n\n[1] \"Mean and St.Dev. of original data set\"\n\n\n[1] 2.301754\n\n\n[1] 1.22338\n\n\nThe mean and standard deviation values of different datasets should not differ significantly but the median statistic can carry more information about the distribution of the data, because of that the dataset produced according to Version 1 may be preferred.",
    "crumbs": [
      "Assignment 1"
    ]
  },
  {
    "objectID": "assignments/assignment-1.html#a-a-brief-summary-for-mr.-demirtas-speech",
    "href": "assignments/assignment-1.html#a-a-brief-summary-for-mr.-demirtas-speech",
    "title": "Assignment 1",
    "section": "(a) A brief summary for Mr. Demirtas` speech;",
    "text": "(a) A brief summary for Mr. Demirtas` speech;\nMr.Demirtas, in his talk, first briefly introduced himself, his background, and his research areas (Replenishment allocation problems, simulation, autonomous vehicles), as well as his work at Invent.ai. The talk can be divided into two parts. In the first part, the definition of data science was given, and its stages were enriched with examples. In the second part, Mr. Demirtas briefly discussed his doctoral thesis and then answered questions about artificial intelligence and data science.\nData science does not always provide exact answers. The key is to ask the right questions, compare the results with the real world, and update models to analyze data correctly. Artificial intelligence and machine learning are tools within data science, but data science is a broader field. Additionally, algorithms and modeling approaches can vary significantly depending on the problem. Data science uses models, algorithms, and analytical techniques to extract meaningful insights from data. Although it has become one of the most popular professions in recent years, artificial intelligence cannot replace data science because the human factor, interpretation, and decision-making processes play a critical role.\nThe data science process consists of problem definition, data collection, exploratory data analysis (EDA), modeling, evaluation, and analyzing results. Problem definition ensures a proper start. For example, Abraham Wald’s analysis of the reasons for the bombing aircraft crashes during World War II illustrates this step. Data can be collected from sources such as sensors and databases. The collected data can be structured or unstructured. Without quality data, it is difficult to obtain accurate results. In the exploratory data analysis (EDA) phase, visualization is an essential tool for understanding the data. For instance, in 1854, Dr. John Snow proved that cholera in London spread through water, not air, by analyzing data.\nIn the model building phase, mathematical models and algorithms are used to derive insights from the data, make predictions, and generate solutions. The fundamental techniques include descriptive (descriptive), predictive (predictive), and prescriptive (prescriptive) analysis. For instance, the weather prediction model developed by Lewis Fry Richardson in 1932 attempted to solve a long-standing problem with the limited tools of that time. Today, however, such problems can be solved in much less time, highlighting the progress of technology and the potential solutions that may emerge in the future. Another example is the mathematical model developed during World War II to ensure sufficient nutrition for soldiers. During the evaluation phase of the model, its success is tested, and issues such as overfitting (when the model memorizes training data too closely) or underfitting (when the model is too simplistic) are analyzed. For example, IBM’s Deep Blue computer tried to win against chess champion Garry Kasparov by memorizing all his moves. However, Kasparov’s unexpected moves revealed the model’s limited learning structure. Finally, during the Deployment & Live Performance stage, the model is integrated into real-world applications, and its performance is monitored. It is important for systems dealing with big data to manage real-time errors and to be scalable.\nAt the end of his talk, Mr. Demirtas discussed his doctoral research, which uses the Cellular Automaton Model to explore how autonomous vehicles can reduce traffic congestion. The goal is to minimize traffic buildup caused by stop-and-go driving or lane changes. The core objective of the thesis is to control when autonomous vehicles should merge, separate, and adjust their speed to optimize traffic flow. By properly guiding autonomous vehicles, maximum efficiency in traffic can be achieved.",
    "crumbs": [
      "Assignment 1"
    ]
  },
  {
    "objectID": "assignments/assignment-1.html#b-mtcars-dataset",
    "href": "assignments/assignment-1.html#b-mtcars-dataset",
    "title": "Assignment 1",
    "section": "(b) “mtcars” Dataset",
    "text": "(b) “mtcars” Dataset\nExploring Statistical Summaries with Custom Functions and Iteration Methods;\n\n\nShow the code\n#Writing a custom summary function\n\ncompute_stats&lt;-function(veri){\n  a&lt;-as.data.frame(matrix(c(quantile(veri),mean(veri),var(veri)),nrow=1,ncol=7))\n  colnames(a)&lt;-c(\"Min.\",\"1st Qu.\",\"Median\",\"3rd Qu.\",\"Max.\",\"Mean.\",\"Var.\")\n  a&lt;-as.list(a)\n  print(a)\n}\n\n\n\n\nShow the code\n#applying the function using a loop\n\nfor(i in 1:ncol(mtcars)){\n  n&lt;-data.frame(colnames(mtcars))\n  print(\"Summary for given data; \")\n  print(n[i,])\n  compute_stats(mtcars[,i])\n}\n\n\n[1] \"Summary for given data; \"\n[1] \"mpg\"\n$Min.\n[1] 10.4\n\n$`1st Qu.`\n[1] 15.425\n\n$Median\n[1] 19.2\n\n$`3rd Qu.`\n[1] 22.8\n\n$Max.\n[1] 33.9\n\n$Mean.\n[1] 20.09062\n\n$Var.\n[1] 36.3241\n\n[1] \"Summary for given data; \"\n[1] \"cyl\"\n$Min.\n[1] 4\n\n$`1st Qu.`\n[1] 4\n\n$Median\n[1] 6\n\n$`3rd Qu.`\n[1] 8\n\n$Max.\n[1] 8\n\n$Mean.\n[1] 6.1875\n\n$Var.\n[1] 3.189516\n\n[1] \"Summary for given data; \"\n[1] \"disp\"\n$Min.\n[1] 71.1\n\n$`1st Qu.`\n[1] 120.825\n\n$Median\n[1] 196.3\n\n$`3rd Qu.`\n[1] 326\n\n$Max.\n[1] 472\n\n$Mean.\n[1] 230.7219\n\n$Var.\n[1] 15360.8\n\n[1] \"Summary for given data; \"\n[1] \"hp\"\n$Min.\n[1] 52\n\n$`1st Qu.`\n[1] 96.5\n\n$Median\n[1] 123\n\n$`3rd Qu.`\n[1] 180\n\n$Max.\n[1] 335\n\n$Mean.\n[1] 146.6875\n\n$Var.\n[1] 4700.867\n\n[1] \"Summary for given data; \"\n[1] \"drat\"\n$Min.\n[1] 2.76\n\n$`1st Qu.`\n[1] 3.08\n\n$Median\n[1] 3.695\n\n$`3rd Qu.`\n[1] 3.92\n\n$Max.\n[1] 4.93\n\n$Mean.\n[1] 3.596563\n\n$Var.\n[1] 0.2858814\n\n[1] \"Summary for given data; \"\n[1] \"wt\"\n$Min.\n[1] 1.513\n\n$`1st Qu.`\n[1] 2.58125\n\n$Median\n[1] 3.325\n\n$`3rd Qu.`\n[1] 3.61\n\n$Max.\n[1] 5.424\n\n$Mean.\n[1] 3.21725\n\n$Var.\n[1] 0.957379\n\n[1] \"Summary for given data; \"\n[1] \"qsec\"\n$Min.\n[1] 14.5\n\n$`1st Qu.`\n[1] 16.8925\n\n$Median\n[1] 17.71\n\n$`3rd Qu.`\n[1] 18.9\n\n$Max.\n[1] 22.9\n\n$Mean.\n[1] 17.84875\n\n$Var.\n[1] 3.193166\n\n[1] \"Summary for given data; \"\n[1] \"vs\"\n$Min.\n[1] 0\n\n$`1st Qu.`\n[1] 0\n\n$Median\n[1] 0\n\n$`3rd Qu.`\n[1] 1\n\n$Max.\n[1] 1\n\n$Mean.\n[1] 0.4375\n\n$Var.\n[1] 0.2540323\n\n[1] \"Summary for given data; \"\n[1] \"am\"\n$Min.\n[1] 0\n\n$`1st Qu.`\n[1] 0\n\n$Median\n[1] 0\n\n$`3rd Qu.`\n[1] 1\n\n$Max.\n[1] 1\n\n$Mean.\n[1] 0.40625\n\n$Var.\n[1] 0.2489919\n\n[1] \"Summary for given data; \"\n[1] \"gear\"\n$Min.\n[1] 3\n\n$`1st Qu.`\n[1] 3\n\n$Median\n[1] 4\n\n$`3rd Qu.`\n[1] 4\n\n$Max.\n[1] 5\n\n$Mean.\n[1] 3.6875\n\n$Var.\n[1] 0.5443548\n\n[1] \"Summary for given data; \"\n[1] \"carb\"\n$Min.\n[1] 1\n\n$`1st Qu.`\n[1] 2\n\n$Median\n[1] 2\n\n$`3rd Qu.`\n[1] 4\n\n$Max.\n[1] 8\n\n$Mean.\n[1] 2.8125\n\n$Var.\n[1] 2.608871\n\n\n\n\nShow the code\n#An alternative approach with sapply and apply.\nsapply(mtcars,compute_stats)\n\n\n$Min.\n[1] 10.4\n\n$`1st Qu.`\n[1] 15.425\n\n$Median\n[1] 19.2\n\n$`3rd Qu.`\n[1] 22.8\n\n$Max.\n[1] 33.9\n\n$Mean.\n[1] 20.09062\n\n$Var.\n[1] 36.3241\n\n$Min.\n[1] 4\n\n$`1st Qu.`\n[1] 4\n\n$Median\n[1] 6\n\n$`3rd Qu.`\n[1] 8\n\n$Max.\n[1] 8\n\n$Mean.\n[1] 6.1875\n\n$Var.\n[1] 3.189516\n\n$Min.\n[1] 71.1\n\n$`1st Qu.`\n[1] 120.825\n\n$Median\n[1] 196.3\n\n$`3rd Qu.`\n[1] 326\n\n$Max.\n[1] 472\n\n$Mean.\n[1] 230.7219\n\n$Var.\n[1] 15360.8\n\n$Min.\n[1] 52\n\n$`1st Qu.`\n[1] 96.5\n\n$Median\n[1] 123\n\n$`3rd Qu.`\n[1] 180\n\n$Max.\n[1] 335\n\n$Mean.\n[1] 146.6875\n\n$Var.\n[1] 4700.867\n\n$Min.\n[1] 2.76\n\n$`1st Qu.`\n[1] 3.08\n\n$Median\n[1] 3.695\n\n$`3rd Qu.`\n[1] 3.92\n\n$Max.\n[1] 4.93\n\n$Mean.\n[1] 3.596563\n\n$Var.\n[1] 0.2858814\n\n$Min.\n[1] 1.513\n\n$`1st Qu.`\n[1] 2.58125\n\n$Median\n[1] 3.325\n\n$`3rd Qu.`\n[1] 3.61\n\n$Max.\n[1] 5.424\n\n$Mean.\n[1] 3.21725\n\n$Var.\n[1] 0.957379\n\n$Min.\n[1] 14.5\n\n$`1st Qu.`\n[1] 16.8925\n\n$Median\n[1] 17.71\n\n$`3rd Qu.`\n[1] 18.9\n\n$Max.\n[1] 22.9\n\n$Mean.\n[1] 17.84875\n\n$Var.\n[1] 3.193166\n\n$Min.\n[1] 0\n\n$`1st Qu.`\n[1] 0\n\n$Median\n[1] 0\n\n$`3rd Qu.`\n[1] 1\n\n$Max.\n[1] 1\n\n$Mean.\n[1] 0.4375\n\n$Var.\n[1] 0.2540323\n\n$Min.\n[1] 0\n\n$`1st Qu.`\n[1] 0\n\n$Median\n[1] 0\n\n$`3rd Qu.`\n[1] 1\n\n$Max.\n[1] 1\n\n$Mean.\n[1] 0.40625\n\n$Var.\n[1] 0.2489919\n\n$Min.\n[1] 3\n\n$`1st Qu.`\n[1] 3\n\n$Median\n[1] 4\n\n$`3rd Qu.`\n[1] 4\n\n$Max.\n[1] 5\n\n$Mean.\n[1] 3.6875\n\n$Var.\n[1] 0.5443548\n\n$Min.\n[1] 1\n\n$`1st Qu.`\n[1] 2\n\n$Median\n[1] 2\n\n$`3rd Qu.`\n[1] 4\n\n$Max.\n[1] 8\n\n$Mean.\n[1] 2.8125\n\n$Var.\n[1] 2.608871\n\n\n        mpg      cyl      disp     hp       drat      wt       qsec    \nMin.    10.4     4        71.1     52       2.76      1.513    14.5    \n1st Qu. 15.425   4        120.825  96.5     3.08      2.58125  16.8925 \nMedian  19.2     6        196.3    123      3.695     3.325    17.71   \n3rd Qu. 22.8     8        326      180      3.92      3.61     18.9    \nMax.    33.9     8        472      335      4.93      5.424    22.9    \nMean.   20.09062 6.1875   230.7219 146.6875 3.596563  3.21725  17.84875\nVar.    36.3241  3.189516 15360.8  4700.867 0.2858814 0.957379 3.193166\n        vs        am        gear      carb    \nMin.    0         0         3         1       \n1st Qu. 0         0         3         2       \nMedian  0         0         4         2       \n3rd Qu. 1         1         4         4       \nMax.    1         1         5         8       \nMean.   0.4375    0.40625   3.6875    2.8125  \nVar.    0.2540323 0.2489919 0.5443548 2.608871\n\n\nShow the code\napply(mtcars,2,compute_stats)\n\n\n$Min.\n[1] 10.4\n\n$`1st Qu.`\n[1] 15.425\n\n$Median\n[1] 19.2\n\n$`3rd Qu.`\n[1] 22.8\n\n$Max.\n[1] 33.9\n\n$Mean.\n[1] 20.09062\n\n$Var.\n[1] 36.3241\n\n$Min.\n[1] 4\n\n$`1st Qu.`\n[1] 4\n\n$Median\n[1] 6\n\n$`3rd Qu.`\n[1] 8\n\n$Max.\n[1] 8\n\n$Mean.\n[1] 6.1875\n\n$Var.\n[1] 3.189516\n\n$Min.\n[1] 71.1\n\n$`1st Qu.`\n[1] 120.825\n\n$Median\n[1] 196.3\n\n$`3rd Qu.`\n[1] 326\n\n$Max.\n[1] 472\n\n$Mean.\n[1] 230.7219\n\n$Var.\n[1] 15360.8\n\n$Min.\n[1] 52\n\n$`1st Qu.`\n[1] 96.5\n\n$Median\n[1] 123\n\n$`3rd Qu.`\n[1] 180\n\n$Max.\n[1] 335\n\n$Mean.\n[1] 146.6875\n\n$Var.\n[1] 4700.867\n\n$Min.\n[1] 2.76\n\n$`1st Qu.`\n[1] 3.08\n\n$Median\n[1] 3.695\n\n$`3rd Qu.`\n[1] 3.92\n\n$Max.\n[1] 4.93\n\n$Mean.\n[1] 3.596563\n\n$Var.\n[1] 0.2858814\n\n$Min.\n[1] 1.513\n\n$`1st Qu.`\n[1] 2.58125\n\n$Median\n[1] 3.325\n\n$`3rd Qu.`\n[1] 3.61\n\n$Max.\n[1] 5.424\n\n$Mean.\n[1] 3.21725\n\n$Var.\n[1] 0.957379\n\n$Min.\n[1] 14.5\n\n$`1st Qu.`\n[1] 16.8925\n\n$Median\n[1] 17.71\n\n$`3rd Qu.`\n[1] 18.9\n\n$Max.\n[1] 22.9\n\n$Mean.\n[1] 17.84875\n\n$Var.\n[1] 3.193166\n\n$Min.\n[1] 0\n\n$`1st Qu.`\n[1] 0\n\n$Median\n[1] 0\n\n$`3rd Qu.`\n[1] 1\n\n$Max.\n[1] 1\n\n$Mean.\n[1] 0.4375\n\n$Var.\n[1] 0.2540323\n\n$Min.\n[1] 0\n\n$`1st Qu.`\n[1] 0\n\n$Median\n[1] 0\n\n$`3rd Qu.`\n[1] 1\n\n$Max.\n[1] 1\n\n$Mean.\n[1] 0.40625\n\n$Var.\n[1] 0.2489919\n\n$Min.\n[1] 3\n\n$`1st Qu.`\n[1] 3\n\n$Median\n[1] 4\n\n$`3rd Qu.`\n[1] 4\n\n$Max.\n[1] 5\n\n$Mean.\n[1] 3.6875\n\n$Var.\n[1] 0.5443548\n\n$Min.\n[1] 1\n\n$`1st Qu.`\n[1] 2\n\n$Median\n[1] 2\n\n$`3rd Qu.`\n[1] 4\n\n$Max.\n[1] 8\n\n$Mean.\n[1] 2.8125\n\n$Var.\n[1] 2.608871\n\n\n$mpg\n$mpg$Min.\n[1] 10.4\n\n$mpg$`1st Qu.`\n[1] 15.425\n\n$mpg$Median\n[1] 19.2\n\n$mpg$`3rd Qu.`\n[1] 22.8\n\n$mpg$Max.\n[1] 33.9\n\n$mpg$Mean.\n[1] 20.09062\n\n$mpg$Var.\n[1] 36.3241\n\n\n$cyl\n$cyl$Min.\n[1] 4\n\n$cyl$`1st Qu.`\n[1] 4\n\n$cyl$Median\n[1] 6\n\n$cyl$`3rd Qu.`\n[1] 8\n\n$cyl$Max.\n[1] 8\n\n$cyl$Mean.\n[1] 6.1875\n\n$cyl$Var.\n[1] 3.189516\n\n\n$disp\n$disp$Min.\n[1] 71.1\n\n$disp$`1st Qu.`\n[1] 120.825\n\n$disp$Median\n[1] 196.3\n\n$disp$`3rd Qu.`\n[1] 326\n\n$disp$Max.\n[1] 472\n\n$disp$Mean.\n[1] 230.7219\n\n$disp$Var.\n[1] 15360.8\n\n\n$hp\n$hp$Min.\n[1] 52\n\n$hp$`1st Qu.`\n[1] 96.5\n\n$hp$Median\n[1] 123\n\n$hp$`3rd Qu.`\n[1] 180\n\n$hp$Max.\n[1] 335\n\n$hp$Mean.\n[1] 146.6875\n\n$hp$Var.\n[1] 4700.867\n\n\n$drat\n$drat$Min.\n[1] 2.76\n\n$drat$`1st Qu.`\n[1] 3.08\n\n$drat$Median\n[1] 3.695\n\n$drat$`3rd Qu.`\n[1] 3.92\n\n$drat$Max.\n[1] 4.93\n\n$drat$Mean.\n[1] 3.596563\n\n$drat$Var.\n[1] 0.2858814\n\n\n$wt\n$wt$Min.\n[1] 1.513\n\n$wt$`1st Qu.`\n[1] 2.58125\n\n$wt$Median\n[1] 3.325\n\n$wt$`3rd Qu.`\n[1] 3.61\n\n$wt$Max.\n[1] 5.424\n\n$wt$Mean.\n[1] 3.21725\n\n$wt$Var.\n[1] 0.957379\n\n\n$qsec\n$qsec$Min.\n[1] 14.5\n\n$qsec$`1st Qu.`\n[1] 16.8925\n\n$qsec$Median\n[1] 17.71\n\n$qsec$`3rd Qu.`\n[1] 18.9\n\n$qsec$Max.\n[1] 22.9\n\n$qsec$Mean.\n[1] 17.84875\n\n$qsec$Var.\n[1] 3.193166\n\n\n$vs\n$vs$Min.\n[1] 0\n\n$vs$`1st Qu.`\n[1] 0\n\n$vs$Median\n[1] 0\n\n$vs$`3rd Qu.`\n[1] 1\n\n$vs$Max.\n[1] 1\n\n$vs$Mean.\n[1] 0.4375\n\n$vs$Var.\n[1] 0.2540323\n\n\n$am\n$am$Min.\n[1] 0\n\n$am$`1st Qu.`\n[1] 0\n\n$am$Median\n[1] 0\n\n$am$`3rd Qu.`\n[1] 1\n\n$am$Max.\n[1] 1\n\n$am$Mean.\n[1] 0.40625\n\n$am$Var.\n[1] 0.2489919\n\n\n$gear\n$gear$Min.\n[1] 3\n\n$gear$`1st Qu.`\n[1] 3\n\n$gear$Median\n[1] 4\n\n$gear$`3rd Qu.`\n[1] 4\n\n$gear$Max.\n[1] 5\n\n$gear$Mean.\n[1] 3.6875\n\n$gear$Var.\n[1] 0.5443548\n\n\n$carb\n$carb$Min.\n[1] 1\n\n$carb$`1st Qu.`\n[1] 2\n\n$carb$Median\n[1] 2\n\n$carb$`3rd Qu.`\n[1] 4\n\n$carb$Max.\n[1] 8\n\n$carb$Mean.\n[1] 2.8125\n\n$carb$Var.\n[1] 2.608871",
    "crumbs": [
      "Assignment 1"
    ]
  },
  {
    "objectID": "assignments/assignment-1.html#c-na_example-dataset",
    "href": "assignments/assignment-1.html#c-na_example-dataset",
    "title": "Assignment 1",
    "section": "(c) “na_example” Dataset",
    "text": "(c) “na_example” Dataset\nNA (missing) values\n\n\nShow the code\n#install.packages(dslabs)\nlibrary(dslabs)\nog_dataset&lt;-na_example\nprint(\"Our dataset:\")\n\n\n[1] \"Our dataset:\"\n\n\nShow the code\nprint(og_dataset)\n\n\n   [1]  2  1  3  2  1  3  1  4  3  2  2 NA  2  2  1  4 NA  1  1  2  1  2  2  1\n  [25]  2  5 NA  2  2  3  1  2  4  1  1  1  4  5  2  3  4  1  2  4  1  1  2  1\n  [49]  5 NA NA NA  1  1  5  1  3  1 NA  4  4  7  3  2 NA NA  1 NA  4  1  2  2\n  [73]  3  2  1  2  2  4  3  4  2  3  1  3  2  1  1  1  3  1 NA  3  1  2  2  1\n  [97]  2  2  1  1  4  1  1  2  3  3  2  2  3  3  3  4  1  1  1  2 NA  4  3  4\n [121]  3  1  2  1 NA NA NA NA  1  5  1  2  1  3  5  3  2  2 NA NA NA NA  3  5\n [145]  3  1  1  4  2  4  3  3 NA  2  3  2  6 NA  1  1  2  2  1  3  1  1  5 NA\n [169] NA  2  4 NA  2  5  1  4  3  3 NA  4  3  1  4  1  1  3  1  1 NA NA  3  5\n [193]  2  2  2  3  1  2  2  3  2  1 NA  2 NA  1 NA NA  2  1  1 NA  3 NA  1  2\n [217]  2  1  3  2  2  1  1  2  3  1  1  1  4  3  4  2  2  1  4  1 NA  5  1  4\n [241] NA  3 NA NA  1  1  5  2  3  3  2  4 NA  3  2  5 NA  2  3  4  6  2  2  2\n [265] NA  2 NA  2 NA  3  3  2  2  4  3  1  4  2 NA  2  4 NA  6  2  3  1 NA  2\n [289]  2 NA  1  1  3  2  3  3  1 NA  1  4  2  1  1  3  2  1  2  3  1 NA  2  3\n [313]  3  2  1  2  3  5  5  1  2  3  3  1 NA NA  1  2  4 NA  2  1  1  1  3  2\n [337]  1  1  3  4 NA  1  2  1  1  3  3 NA  1  1  3  5  3  2  3  4  1  4  3  1\n [361] NA  2  1  2  2  1  2  2  6  1  2  4  5 NA  3  4  2  1  1  4  2  1  1  1\n [385]  1  2  1  4  4  1  3 NA  3  3 NA  2 NA  1  2  1  1  4  2  1  4  4 NA  1\n [409]  2 NA  3  2  2  2  1  4  3  6  1  2  3  1  3  2  2  2  1  1  3  2  1  1\n [433]  1  3  2  2 NA  4  4  4  1  1 NA  4  3 NA  1  3  1  3  2  4  2  2  2  3\n [457]  2  1  4  3 NA  1  4  3  1  3  2 NA  3 NA  1  3  1  4  1  1  1  2  4  3\n [481]  1  2  2  2  3  2  3  1  1 NA  3  2  1  1  2 NA  2  2  2  3  3  1  1  2\n [505] NA  1  2  1  1  3  3  1  3  1  1  1  1  1  2  5  1  1  2  2  1  1 NA  1\n [529]  4  1  2  4  1  3  2 NA  1  1 NA  2  1  1  4  2  3  3  1  5  3  1  1  2\n [553] NA  1  1  3  1  3  2  4 NA  2  3  2  1  2  1  1  1  2  2  3  1  5  2 NA\n [577]  2 NA  3  2  2  2  1  5  3  2  3  1 NA  3  1  2  2  2  1  2  2  4 NA  6\n [601]  1  2 NA  1  1  2  2  3 NA  3  2  3  3  4  2 NA  2 NA  4 NA  1  1  2  2\n [625]  3  1  1  1  3 NA  2  5 NA  7  1 NA  4  3  3  1 NA  1  1  1  1  3  2  4\n [649]  2  2  3 NA NA  1  4  3  2  2  2  3  2  4  2  2  4 NA NA NA  6  3  3  1\n [673]  4  4  2  1 NA  1  6 NA  3  3  2  1  1  6 NA  1  5  1 NA  2  6  2 NA  4\n [697]  1  3  1  2 NA  1  1  3  1  2  4  2  1  3  2  4  3  2  2  1  1  5  6  4\n [721]  2  2  2  2  4 NA  1  2  2  2  2  4  5 NA NA NA  4  3  3  3  2  4  2  4\n [745] NA NA NA NA  2  1 NA  2  4  3  2 NA  2  3  1  3  4 NA  1  2  1  2 NA  3\n [769]  1  2  1  2  1  2  1  2  2  2  2  1  1  3  3  1  3  4  3 NA NA  4  2  3\n [793]  2  1  3  2  4  2  2  3  1  2  4  3  3  4 NA  1  4  2  1  1  1  3  1  5\n [817]  2  2  4  2 NA  1  3  1  2 NA  1  2  1  2  1 NA  1  3  2  3  2 NA  2  1\n [841]  4  2 NA NA NA  2  4  2 NA NA  3  1 NA  5  5  2  2  2 NA  2  1  3  1  3\n [865]  2  4  2  4 NA  4  1  2  3  2  3  3  2  3  2  2  2  1  3  2  4  2 NA  3\n [889]  3  2  2 NA NA  3  2  1  2  4  1  1  1  1  4  3  2 NA  3  2 NA  1 NA  3\n [913]  2  1  1  1  2 NA  2  2  3  3  2 NA NA  4  5  2  2  2  1  2  3  1  3  3\n [937]  4  3 NA  1  1  1 NA  4  3  5  1  1  2 NA  2  2  2  2  5  2  2  3  1  2\n [961]  3 NA  1  2 NA NA  2 NA  3  1  1  2  5  3  5  1  1  4 NA  2  1  3  1  1\n [985]  2  4  3  3  3 NA  1  1  2  2  1  1  2  2 NA  2\n\n\nShow the code\n#Total count of NA values \nsum&lt;-0\nfor(i in 1:1000){\nifelse(is.na(og_dataset[i])=='TRUE',sum&lt;-sum+1,sum&lt;-sum)\n}\nprint(\"Total count of NA values\")\n\n\n[1] \"Total count of NA values\"\n\n\nShow the code\nprint(sum)\n\n\n[1] 145\n\n\nShow the code\n# Index positions of NA values\nindex&lt;-matrix(data=rep(0,sum))\nb&lt;-1\nfor(i in 1:1000){\nif(is.na(og_dataset[i])=='TRUE'){\n  index[b]&lt;-i\n  b&lt;-b+1\n  }\n}\nprint(\"Index positions of NA values\")\n\n\n[1] \"Index positions of NA values\"\n\n\nShow the code\nprint(index)\n\n\n       [,1]\n  [1,]   12\n  [2,]   17\n  [3,]   27\n  [4,]   50\n  [5,]   51\n  [6,]   52\n  [7,]   59\n  [8,]   65\n  [9,]   66\n [10,]   68\n [11,]   91\n [12,]  117\n [13,]  125\n [14,]  126\n [15,]  127\n [16,]  128\n [17,]  139\n [18,]  140\n [19,]  141\n [20,]  142\n [21,]  153\n [22,]  158\n [23,]  168\n [24,]  169\n [25,]  172\n [26,]  179\n [27,]  189\n [28,]  190\n [29,]  203\n [30,]  205\n [31,]  207\n [32,]  208\n [33,]  212\n [34,]  214\n [35,]  237\n [36,]  241\n [37,]  243\n [38,]  244\n [39,]  253\n [40,]  257\n [41,]  265\n [42,]  267\n [43,]  269\n [44,]  279\n [45,]  282\n [46,]  287\n [47,]  290\n [48,]  298\n [49,]  310\n [50,]  325\n [51,]  326\n [52,]  330\n [53,]  341\n [54,]  348\n [55,]  361\n [56,]  374\n [57,]  392\n [58,]  395\n [59,]  397\n [60,]  407\n [61,]  410\n [62,]  437\n [63,]  443\n [64,]  446\n [65,]  461\n [66,]  468\n [67,]  470\n [68,]  490\n [69,]  496\n [70,]  505\n [71,]  527\n [72,]  536\n [73,]  539\n [74,]  553\n [75,]  561\n [76,]  576\n [77,]  578\n [78,]  589\n [79,]  599\n [80,]  603\n [81,]  609\n [82,]  616\n [83,]  618\n [84,]  620\n [85,]  630\n [86,]  633\n [87,]  636\n [88,]  641\n [89,]  652\n [90,]  653\n [91,]  666\n [92,]  667\n [93,]  668\n [94,]  677\n [95,]  680\n [96,]  687\n [97,]  691\n [98,]  695\n [99,]  701\n[100,]  726\n[101,]  734\n[102,]  735\n[103,]  736\n[104,]  745\n[105,]  746\n[106,]  747\n[107,]  748\n[108,]  751\n[109,]  756\n[110,]  762\n[111,]  767\n[112,]  788\n[113,]  789\n[114,]  807\n[115,]  821\n[116,]  826\n[117,]  832\n[118,]  838\n[119,]  843\n[120,]  844\n[121,]  845\n[122,]  849\n[123,]  850\n[124,]  853\n[125,]  859\n[126,]  869\n[127,]  887\n[128,]  892\n[129,]  893\n[130,]  906\n[131,]  909\n[132,]  911\n[133,]  918\n[134,]  924\n[135,]  925\n[136,]  939\n[137,]  943\n[138,]  950\n[139,]  962\n[140,]  965\n[141,]  966\n[142,]  968\n[143,]  979\n[144,]  990\n[145,]  999\n\n\nShow the code\n#Mean and standard deviation of dataset (ignore NA s in calculations)\nprint(\"Mean and St.Dev. of original data set\")\n\n\n[1] \"Mean and St.Dev. of original data set\"\n\n\nShow the code\nprint(mean(og_dataset,na.rm=TRUE))#na.rm=TRUE means ignoring NA values in computation\n\n\n[1] 2.301754\n\n\nShow the code\nprint(sd(og_dataset,na.rm=TRUE))\n\n\n[1] 1.22338\n\n\nShow the code\n#Handling missing values\n#Version1\nv1_dataset&lt;-matrix(data=rep(0,1000))\nv2_dataset&lt;-matrix(data=rep(0,1000))\nrandom&lt;-(sample(1:1000,1))\nfor(i in 1:1000){\nifelse(is.na(og_dataset[i])==TRUE,(v1_dataset[i]&lt;-median(og_dataset,na.rm = TRUE))&&(v2_dataset[i]&lt;-og_dataset[random]),(v1_dataset[i]&lt;-og_dataset[i])&&(v2_dataset[i]&lt;-og_dataset[i]))\n }\n\n#Compare the results\nprint(\"Mean and St.Dev. of Version 1 data set\")\n\n\n[1] \"Mean and St.Dev. of Version 1 data set\"\n\n\nShow the code\nmean(v1_dataset)\n\n\n[1] 2.258\n\n\nShow the code\nsd(v1_dataset)\n\n\n[1] 1.136102\n\n\nShow the code\nprint(\"Mean and St.Dev. of Version 2 data set\")\n\n\n[1] \"Mean and St.Dev. of Version 2 data set\"\n\n\nShow the code\nmean(v2_dataset)\n\n\n[1] 2.113\n\n\nShow the code\nsd(v2_dataset)\n\n\n[1] 1.220541\n\n\nShow the code\nprint(\"Mean and St.Dev. of original data set\")\n\n\n[1] \"Mean and St.Dev. of original data set\"\n\n\nShow the code\nmean(og_dataset,na.rm=TRUE)\n\n\n[1] 2.301754\n\n\nShow the code\nsd(og_dataset,na.rm=TRUE)\n\n\n[1] 1.22338\n\n\nThe mean and standard deviation values of different datasets should not differ significantly but the median statistic can carry more information about the distribution of the data, because of that the dataset produced according to Version 1 may be preferred.",
    "crumbs": [
      "Assignment 1"
    ]
  },
  {
    "objectID": "project.html#footnotes",
    "href": "project.html#footnotes",
    "title": "Is Ignorance Truly Bliss*? Relationship between Education, Gender & Happiness",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nTurkish Statistical Institute (TURKSTAT). (2024). Life Satisfaction Survey, 2023. Retrieved from https://data.tuik.gov.tr/↩︎\nTurkish Statistical Institute (TURKSTAT).(2024). Population Statics Portal, 2024. Retrieved from https://nip.tuik.gov.tr/↩︎"
  }
]