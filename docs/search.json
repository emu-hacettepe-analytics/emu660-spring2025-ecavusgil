[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Welcome to My Analytics Lab",
    "section": "",
    "text": "Hello!! My name is Ece Çavuşgil.\nThis is my personal webpage.\nPlease stay tuned to follow my works on data analytics, blog posts, and more.\n\n\n\n Back to top"
  },
  {
    "objectID": "project.html",
    "href": "project.html",
    "title": "Project X",
    "section": "",
    "text": "Welcome to my/our project page.\nKeep an eye on this space to stay updated with my project activities.\n(The titles below are provided as examples; please feel free to adjust them as necessary.)"
  },
  {
    "objectID": "project.html#data-source",
    "href": "project.html#data-source",
    "title": "Project X",
    "section": "2.1 Data Source",
    "text": "2.1 Data Source\nxxxxxx"
  },
  {
    "objectID": "project.html#general-information-about-data",
    "href": "project.html#general-information-about-data",
    "title": "Project X",
    "section": "2.2 General Information About Data",
    "text": "2.2 General Information About Data\nxxxxxx"
  },
  {
    "objectID": "project.html#reason-of-choice",
    "href": "project.html#reason-of-choice",
    "title": "Project X",
    "section": "2.3 Reason of Choice",
    "text": "2.3 Reason of Choice\nxxxxxx"
  },
  {
    "objectID": "project.html#preprocessing",
    "href": "project.html#preprocessing",
    "title": "Project X",
    "section": "2.4 Preprocessing",
    "text": "2.4 Preprocessing\nxxxxxx"
  },
  {
    "objectID": "project.html#exploratory-data-analysis",
    "href": "project.html#exploratory-data-analysis",
    "title": "Project X",
    "section": "3.1 Exploratory Data Analysis",
    "text": "3.1 Exploratory Data Analysis\nxxxxxx"
  },
  {
    "objectID": "project.html#trend-analysis",
    "href": "project.html#trend-analysis",
    "title": "Project X",
    "section": "3.2 Trend Analysis",
    "text": "3.2 Trend Analysis\nxxxxxx"
  },
  {
    "objectID": "project.html#model-fitting",
    "href": "project.html#model-fitting",
    "title": "Project X",
    "section": "3.3 Model Fitting",
    "text": "3.3 Model Fitting\nxxxxxx"
  },
  {
    "objectID": "project.html#results",
    "href": "project.html#results",
    "title": "Project X",
    "section": "3.4 Results",
    "text": "3.4 Results\nxxxxxx"
  },
  {
    "objectID": "assignments.html",
    "href": "assignments.html",
    "title": "My Assignments",
    "section": "",
    "text": "On this page, I showcase the assignment I conducted for the [ Spring 2024-2025] EMU660 Decision Making with Analytics course.\nPlease use left menu to navigate through my assignments.\n\n\n\n Back to top",
    "crumbs": [
      "My Assignments"
    ]
  },
  {
    "objectID": "about.html#employements",
    "href": "about.html#employements",
    "title": "About Me",
    "section": "Employements",
    "text": "Employements\n\nLUPE Consulting, SAP Consultant , 2020-2021"
  },
  {
    "objectID": "about.html#internships",
    "href": "about.html#internships",
    "title": "About Me",
    "section": "Internships",
    "text": "Internships\n\nFNSS Defense Systems, Intern, 2017\nTurkish Aerospace Industries, Intern 2018"
  },
  {
    "objectID": "posts.html",
    "href": "posts.html",
    "title": "My Blog",
    "section": "",
    "text": "This page is under construction.\n\n\n\n Back to top"
  },
  {
    "objectID": "docs/assignments/assignment-1.html",
    "href": "docs/assignments/assignment-1.html",
    "title": "Assignment 1",
    "section": "",
    "text": "1 + 1\n\n[1] 2\n\n\nMy first assignment has two parts."
  },
  {
    "objectID": "assignments/assignment-1.html",
    "href": "assignments/assignment-1.html",
    "title": "Assignment 1",
    "section": "",
    "text": "My first assignment has three parts.",
    "crumbs": [
      "Assignment 1"
    ]
  },
  {
    "objectID": "assignments/assignment-2.html",
    "href": "assignments/assignment-2.html",
    "title": "Assignment 2",
    "section": "",
    "text": "Assignment 2\n\n1 + 1\n\n[1] 2\n\n\n\n\n\n\n Back to top",
    "crumbs": [
      "Assignment 2"
    ]
  },
  {
    "objectID": "assignments/assignment-1.html#a",
    "href": "assignments/assignment-1.html#a",
    "title": "Assignment 1",
    "section": "(a)",
    "text": "(a)\nA brief summary for Mr. Demirtas` speech;\nMr.Demirtas, in his talk, first briefly introduced himself, his background, and his research areas (Replenishment allocation problems, simulation, autonomous vehicles), as well as his work at Invent.ai. The talk can be divided into two parts. In the first part, the definition of data science was given, and its stages were enriched with examples. In the second part, Mr. Demirtas briefly discussed his doctoral thesis and then answered questions about artificial intelligence and data science.\nData science does not always provide exact answers. The key is to ask the right questions, compare the results with the real world, and update models to analyze data correctly. Artificial intelligence and machine learning are tools within data science, but data science is a broader field. Additionally, algorithms and modeling approaches can vary significantly depending on the problem. Data science uses models, algorithms, and analytical techniques to extract meaningful insights from data. Although it has become one of the most popular professions in recent years, artificial intelligence cannot replace data science because the human factor, interpretation, and decision-making processes play a critical role.\nThe data science process consists of problem definition, data collection, exploratory data analysis (EDA), modeling, evaluation, and analyzing results. Problem definition ensures a proper start. For example, Abraham Wald’s analysis of the reasons for the bombing aircraft crashes during World War II illustrates this step. Data can be collected from sources such as sensors and databases. The collected data can be structured or unstructured. Without quality data, it is difficult to obtain accurate results. In the exploratory data analysis (EDA) phase, visualization is an essential tool for understanding the data. For instance, in 1854, Dr. John Snow proved that cholera in London spread through water, not air, by analyzing data.\nIn the model building phase, mathematical models and algorithms are used to derive insights from the data, make predictions, and generate solutions. The fundamental techniques include descriptive (descriptive), predictive (predictive), and prescriptive (prescriptive) analysis. For instance, the weather prediction model developed by Lewis Fry Richardson in 1932 attempted to solve a long-standing problem with the limited tools of that time. Today, however, such problems can be solved in much less time, highlighting the progress of technology and the potential solutions that may emerge in the future. Another example is the mathematical model developed during World War II to ensure sufficient nutrition for soldiers. During the evaluation phase of the model, its success is tested, and issues such as overfitting (when the model memorizes training data too closely) or underfitting (when the model is too simplistic) are analyzed. For example, IBM’s Deep Blue computer tried to win against chess champion Garry Kasparov by memorizing all his moves. However, Kasparov’s unexpected moves revealed the model’s limited learning structure. Finally, during the Deployment & Live Performance stage, the model is integrated into real-world applications, and its performance is monitored. It is important for systems dealing with big data to manage real-time errors and to be scalable.\nAt the end of his talk, Mr. Demirtas discussed his doctoral research, which uses the Cellular Automaton Model to explore how autonomous vehicles can reduce traffic congestion. The goal is to minimize traffic buildup caused by stop-and-go driving or lane changes. The core objective of the thesis is to control when autonomous vehicles should merge, separate, and adjust their speed to optimize traffic flow. By properly guiding autonomous vehicles, maximum efficiency in traffic can be achieved.",
    "crumbs": [
      "Assignment 1"
    ]
  },
  {
    "objectID": "assignments/assignment-1.html#b",
    "href": "assignments/assignment-1.html#b",
    "title": "Assignment 1",
    "section": "(b)",
    "text": "(b)\nExploring Statistical Summaries with Custom Functions and Iteration Methods;\n\n\n[1] \"Summary for given data; \"\n[1] \"mpg\"\n$Min.\n[1] 10.4\n\n$`1st Qu.`\n[1] 15.425\n\n$Median\n[1] 19.2\n\n$`3rd Qu.`\n[1] 22.8\n\n$Max.\n[1] 33.9\n\n$Mean.\n[1] 20.09062\n\n$Var.\n[1] 36.3241\n\n[1] \"Summary for given data; \"\n[1] \"cyl\"\n$Min.\n[1] 4\n\n$`1st Qu.`\n[1] 4\n\n$Median\n[1] 6\n\n$`3rd Qu.`\n[1] 8\n\n$Max.\n[1] 8\n\n$Mean.\n[1] 6.1875\n\n$Var.\n[1] 3.189516\n\n[1] \"Summary for given data; \"\n[1] \"disp\"\n$Min.\n[1] 71.1\n\n$`1st Qu.`\n[1] 120.825\n\n$Median\n[1] 196.3\n\n$`3rd Qu.`\n[1] 326\n\n$Max.\n[1] 472\n\n$Mean.\n[1] 230.7219\n\n$Var.\n[1] 15360.8\n\n[1] \"Summary for given data; \"\n[1] \"hp\"\n$Min.\n[1] 52\n\n$`1st Qu.`\n[1] 96.5\n\n$Median\n[1] 123\n\n$`3rd Qu.`\n[1] 180\n\n$Max.\n[1] 335\n\n$Mean.\n[1] 146.6875\n\n$Var.\n[1] 4700.867\n\n[1] \"Summary for given data; \"\n[1] \"drat\"\n$Min.\n[1] 2.76\n\n$`1st Qu.`\n[1] 3.08\n\n$Median\n[1] 3.695\n\n$`3rd Qu.`\n[1] 3.92\n\n$Max.\n[1] 4.93\n\n$Mean.\n[1] 3.596563\n\n$Var.\n[1] 0.2858814\n\n[1] \"Summary for given data; \"\n[1] \"wt\"\n$Min.\n[1] 1.513\n\n$`1st Qu.`\n[1] 2.58125\n\n$Median\n[1] 3.325\n\n$`3rd Qu.`\n[1] 3.61\n\n$Max.\n[1] 5.424\n\n$Mean.\n[1] 3.21725\n\n$Var.\n[1] 0.957379\n\n[1] \"Summary for given data; \"\n[1] \"qsec\"\n$Min.\n[1] 14.5\n\n$`1st Qu.`\n[1] 16.8925\n\n$Median\n[1] 17.71\n\n$`3rd Qu.`\n[1] 18.9\n\n$Max.\n[1] 22.9\n\n$Mean.\n[1] 17.84875\n\n$Var.\n[1] 3.193166\n\n[1] \"Summary for given data; \"\n[1] \"vs\"\n$Min.\n[1] 0\n\n$`1st Qu.`\n[1] 0\n\n$Median\n[1] 0\n\n$`3rd Qu.`\n[1] 1\n\n$Max.\n[1] 1\n\n$Mean.\n[1] 0.4375\n\n$Var.\n[1] 0.2540323\n\n[1] \"Summary for given data; \"\n[1] \"am\"\n$Min.\n[1] 0\n\n$`1st Qu.`\n[1] 0\n\n$Median\n[1] 0\n\n$`3rd Qu.`\n[1] 1\n\n$Max.\n[1] 1\n\n$Mean.\n[1] 0.40625\n\n$Var.\n[1] 0.2489919\n\n[1] \"Summary for given data; \"\n[1] \"gear\"\n$Min.\n[1] 3\n\n$`1st Qu.`\n[1] 3\n\n$Median\n[1] 4\n\n$`3rd Qu.`\n[1] 4\n\n$Max.\n[1] 5\n\n$Mean.\n[1] 3.6875\n\n$Var.\n[1] 0.5443548\n\n[1] \"Summary for given data; \"\n[1] \"carb\"\n$Min.\n[1] 1\n\n$`1st Qu.`\n[1] 2\n\n$Median\n[1] 2\n\n$`3rd Qu.`\n[1] 4\n\n$Max.\n[1] 8\n\n$Mean.\n[1] 2.8125\n\n$Var.\n[1] 2.608871\n\n\n\n\n$Min.\n[1] 10.4\n\n$`1st Qu.`\n[1] 15.425\n\n$Median\n[1] 19.2\n\n$`3rd Qu.`\n[1] 22.8\n\n$Max.\n[1] 33.9\n\n$Mean.\n[1] 20.09062\n\n$Var.\n[1] 36.3241\n\n$Min.\n[1] 4\n\n$`1st Qu.`\n[1] 4\n\n$Median\n[1] 6\n\n$`3rd Qu.`\n[1] 8\n\n$Max.\n[1] 8\n\n$Mean.\n[1] 6.1875\n\n$Var.\n[1] 3.189516\n\n$Min.\n[1] 71.1\n\n$`1st Qu.`\n[1] 120.825\n\n$Median\n[1] 196.3\n\n$`3rd Qu.`\n[1] 326\n\n$Max.\n[1] 472\n\n$Mean.\n[1] 230.7219\n\n$Var.\n[1] 15360.8\n\n$Min.\n[1] 52\n\n$`1st Qu.`\n[1] 96.5\n\n$Median\n[1] 123\n\n$`3rd Qu.`\n[1] 180\n\n$Max.\n[1] 335\n\n$Mean.\n[1] 146.6875\n\n$Var.\n[1] 4700.867\n\n$Min.\n[1] 2.76\n\n$`1st Qu.`\n[1] 3.08\n\n$Median\n[1] 3.695\n\n$`3rd Qu.`\n[1] 3.92\n\n$Max.\n[1] 4.93\n\n$Mean.\n[1] 3.596563\n\n$Var.\n[1] 0.2858814\n\n$Min.\n[1] 1.513\n\n$`1st Qu.`\n[1] 2.58125\n\n$Median\n[1] 3.325\n\n$`3rd Qu.`\n[1] 3.61\n\n$Max.\n[1] 5.424\n\n$Mean.\n[1] 3.21725\n\n$Var.\n[1] 0.957379\n\n$Min.\n[1] 14.5\n\n$`1st Qu.`\n[1] 16.8925\n\n$Median\n[1] 17.71\n\n$`3rd Qu.`\n[1] 18.9\n\n$Max.\n[1] 22.9\n\n$Mean.\n[1] 17.84875\n\n$Var.\n[1] 3.193166\n\n$Min.\n[1] 0\n\n$`1st Qu.`\n[1] 0\n\n$Median\n[1] 0\n\n$`3rd Qu.`\n[1] 1\n\n$Max.\n[1] 1\n\n$Mean.\n[1] 0.4375\n\n$Var.\n[1] 0.2540323\n\n$Min.\n[1] 0\n\n$`1st Qu.`\n[1] 0\n\n$Median\n[1] 0\n\n$`3rd Qu.`\n[1] 1\n\n$Max.\n[1] 1\n\n$Mean.\n[1] 0.40625\n\n$Var.\n[1] 0.2489919\n\n$Min.\n[1] 3\n\n$`1st Qu.`\n[1] 3\n\n$Median\n[1] 4\n\n$`3rd Qu.`\n[1] 4\n\n$Max.\n[1] 5\n\n$Mean.\n[1] 3.6875\n\n$Var.\n[1] 0.5443548\n\n$Min.\n[1] 1\n\n$`1st Qu.`\n[1] 2\n\n$Median\n[1] 2\n\n$`3rd Qu.`\n[1] 4\n\n$Max.\n[1] 8\n\n$Mean.\n[1] 2.8125\n\n$Var.\n[1] 2.608871\n\n\n$mpg\n$mpg$Min.\n[1] 10.4\n\n$mpg$`1st Qu.`\n[1] 15.425\n\n$mpg$Median\n[1] 19.2\n\n$mpg$`3rd Qu.`\n[1] 22.8\n\n$mpg$Max.\n[1] 33.9\n\n$mpg$Mean.\n[1] 20.09062\n\n$mpg$Var.\n[1] 36.3241\n\n\n$cyl\n$cyl$Min.\n[1] 4\n\n$cyl$`1st Qu.`\n[1] 4\n\n$cyl$Median\n[1] 6\n\n$cyl$`3rd Qu.`\n[1] 8\n\n$cyl$Max.\n[1] 8\n\n$cyl$Mean.\n[1] 6.1875\n\n$cyl$Var.\n[1] 3.189516\n\n\n$disp\n$disp$Min.\n[1] 71.1\n\n$disp$`1st Qu.`\n[1] 120.825\n\n$disp$Median\n[1] 196.3\n\n$disp$`3rd Qu.`\n[1] 326\n\n$disp$Max.\n[1] 472\n\n$disp$Mean.\n[1] 230.7219\n\n$disp$Var.\n[1] 15360.8\n\n\n$hp\n$hp$Min.\n[1] 52\n\n$hp$`1st Qu.`\n[1] 96.5\n\n$hp$Median\n[1] 123\n\n$hp$`3rd Qu.`\n[1] 180\n\n$hp$Max.\n[1] 335\n\n$hp$Mean.\n[1] 146.6875\n\n$hp$Var.\n[1] 4700.867\n\n\n$drat\n$drat$Min.\n[1] 2.76\n\n$drat$`1st Qu.`\n[1] 3.08\n\n$drat$Median\n[1] 3.695\n\n$drat$`3rd Qu.`\n[1] 3.92\n\n$drat$Max.\n[1] 4.93\n\n$drat$Mean.\n[1] 3.596563\n\n$drat$Var.\n[1] 0.2858814\n\n\n$wt\n$wt$Min.\n[1] 1.513\n\n$wt$`1st Qu.`\n[1] 2.58125\n\n$wt$Median\n[1] 3.325\n\n$wt$`3rd Qu.`\n[1] 3.61\n\n$wt$Max.\n[1] 5.424\n\n$wt$Mean.\n[1] 3.21725\n\n$wt$Var.\n[1] 0.957379\n\n\n$qsec\n$qsec$Min.\n[1] 14.5\n\n$qsec$`1st Qu.`\n[1] 16.8925\n\n$qsec$Median\n[1] 17.71\n\n$qsec$`3rd Qu.`\n[1] 18.9\n\n$qsec$Max.\n[1] 22.9\n\n$qsec$Mean.\n[1] 17.84875\n\n$qsec$Var.\n[1] 3.193166\n\n\n$vs\n$vs$Min.\n[1] 0\n\n$vs$`1st Qu.`\n[1] 0\n\n$vs$Median\n[1] 0\n\n$vs$`3rd Qu.`\n[1] 1\n\n$vs$Max.\n[1] 1\n\n$vs$Mean.\n[1] 0.4375\n\n$vs$Var.\n[1] 0.2540323\n\n\n$am\n$am$Min.\n[1] 0\n\n$am$`1st Qu.`\n[1] 0\n\n$am$Median\n[1] 0\n\n$am$`3rd Qu.`\n[1] 1\n\n$am$Max.\n[1] 1\n\n$am$Mean.\n[1] 0.40625\n\n$am$Var.\n[1] 0.2489919\n\n\n$gear\n$gear$Min.\n[1] 3\n\n$gear$`1st Qu.`\n[1] 3\n\n$gear$Median\n[1] 4\n\n$gear$`3rd Qu.`\n[1] 4\n\n$gear$Max.\n[1] 5\n\n$gear$Mean.\n[1] 3.6875\n\n$gear$Var.\n[1] 0.5443548\n\n\n$carb\n$carb$Min.\n[1] 1\n\n$carb$`1st Qu.`\n[1] 2\n\n$carb$Median\n[1] 2\n\n$carb$`3rd Qu.`\n[1] 4\n\n$carb$Max.\n[1] 8\n\n$carb$Mean.\n[1] 2.8125\n\n$carb$Var.\n[1] 2.608871",
    "crumbs": [
      "Assignment 1"
    ]
  },
  {
    "objectID": "assignments/assignment-1.html#c",
    "href": "assignments/assignment-1.html#c",
    "title": "Assignment 1",
    "section": "(c)",
    "text": "(c)\nNA (missing) values\n\n\n[1] 12\n[1] 17\n[1] 27\n[1] 50\n[1] 51\n[1] 52\n[1] 59\n[1] 65\n[1] 66\n[1] 68\n[1] 91\n[1] 117\n[1] 125\n[1] 126\n[1] 127\n[1] 128\n[1] 139\n[1] 140\n[1] 141\n[1] 142\n[1] 153\n[1] 158\n[1] 168\n[1] 169\n[1] 172\n[1] 179\n[1] 189\n[1] 190\n[1] 203\n[1] 205\n[1] 207\n[1] 208\n[1] 212\n[1] 214\n[1] 237\n[1] 241\n[1] 243\n[1] 244\n[1] 253\n[1] 257\n[1] 265\n[1] 267\n[1] 269\n[1] 279\n[1] 282\n[1] 287\n[1] 290\n[1] 298\n[1] 310\n[1] 325\n[1] 326\n[1] 330\n[1] 341\n[1] 348\n[1] 361\n[1] 374\n[1] 392\n[1] 395\n[1] 397\n[1] 407\n[1] 410\n[1] 437\n[1] 443\n[1] 446\n[1] 461\n[1] 468\n[1] 470\n[1] 490\n[1] 496\n[1] 505\n[1] 527\n[1] 536\n[1] 539\n[1] 553\n[1] 561\n[1] 576\n[1] 578\n[1] 589\n[1] 599\n[1] 603\n[1] 609\n[1] 616\n[1] 618\n[1] 620\n[1] 630\n[1] 633\n[1] 636\n[1] 641\n[1] 652\n[1] 653\n[1] 666\n[1] 667\n[1] 668\n[1] 677\n[1] 680\n[1] 687\n[1] 691\n[1] 695\n[1] 701\n[1] 726\n[1] 734\n[1] 735\n[1] 736\n[1] 745\n[1] 746\n[1] 747\n[1] 748\n[1] 751\n[1] 756\n[1] 762\n[1] 767\n[1] 788\n[1] 789\n[1] 807\n[1] 821\n[1] 826\n[1] 832\n[1] 838\n[1] 843\n[1] 844\n[1] 845\n[1] 849\n[1] 850\n[1] 853\n[1] 859\n[1] 869\n[1] 887\n[1] 892\n[1] 893\n[1] 906\n[1] 909\n[1] 911\n[1] 918\n[1] 924\n[1] 925\n[1] 939\n[1] 943\n[1] 950\n[1] 962\n[1] 965\n[1] 966\n[1] 968\n[1] 979\n[1] 990\n[1] 999\n\n\n[1] TRUE\n\n\n[1] \"Mean and St.Dev. of original data set\"\n\n\n[1] 2.301754\n\n\n[1] 1.22338\n\n\n[1] \"Mean and St.Dev. of Version 1 data set\"\n\n\n[1] 2.258\n\n\n[1] 1.136102\n\n\n[1] \"Mean and St.Dev. of Version 2 data set\"\n\n\n[1] 2.403\n\n\n[1] 1.157554\n\n\n[1] \"Mean and St.Dev. of original data set\"\n\n\n[1] 2.301754\n\n\n[1] 1.22338\n\n\nThe mean and standard deviation values of different datasets should not differ significantly but the median statistic can carry more information about the distribution of the data, because of that the dataset produced according to Version 1 may be preferred.",
    "crumbs": [
      "Assignment 1"
    ]
  },
  {
    "objectID": "assignments/assignment-1.html#a-a-brief-summary-for-mr.-demirtas-speech",
    "href": "assignments/assignment-1.html#a-a-brief-summary-for-mr.-demirtas-speech",
    "title": "Assignment 1",
    "section": "(a) A brief summary for Mr. Demirtas` speech;",
    "text": "(a) A brief summary for Mr. Demirtas` speech;\nMr.Demirtas, in his talk, first briefly introduced himself, his background, and his research areas (Replenishment allocation problems, simulation, autonomous vehicles), as well as his work at Invent.ai. The talk can be divided into two parts. In the first part, the definition of data science was given, and its stages were enriched with examples. In the second part, Mr. Demirtas briefly discussed his doctoral thesis and then answered questions about artificial intelligence and data science.\nData science does not always provide exact answers. The key is to ask the right questions, compare the results with the real world, and update models to analyze data correctly. Artificial intelligence and machine learning are tools within data science, but data science is a broader field. Additionally, algorithms and modeling approaches can vary significantly depending on the problem. Data science uses models, algorithms, and analytical techniques to extract meaningful insights from data. Although it has become one of the most popular professions in recent years, artificial intelligence cannot replace data science because the human factor, interpretation, and decision-making processes play a critical role.\nThe data science process consists of problem definition, data collection, exploratory data analysis (EDA), modeling, evaluation, and analyzing results. Problem definition ensures a proper start. For example, Abraham Wald’s analysis of the reasons for the bombing aircraft crashes during World War II illustrates this step. Data can be collected from sources such as sensors and databases. The collected data can be structured or unstructured. Without quality data, it is difficult to obtain accurate results. In the exploratory data analysis (EDA) phase, visualization is an essential tool for understanding the data. For instance, in 1854, Dr. John Snow proved that cholera in London spread through water, not air, by analyzing data.\nIn the model building phase, mathematical models and algorithms are used to derive insights from the data, make predictions, and generate solutions. The fundamental techniques include descriptive (descriptive), predictive (predictive), and prescriptive (prescriptive) analysis. For instance, the weather prediction model developed by Lewis Fry Richardson in 1932 attempted to solve a long-standing problem with the limited tools of that time. Today, however, such problems can be solved in much less time, highlighting the progress of technology and the potential solutions that may emerge in the future. Another example is the mathematical model developed during World War II to ensure sufficient nutrition for soldiers. During the evaluation phase of the model, its success is tested, and issues such as overfitting (when the model memorizes training data too closely) or underfitting (when the model is too simplistic) are analyzed. For example, IBM’s Deep Blue computer tried to win against chess champion Garry Kasparov by memorizing all his moves. However, Kasparov’s unexpected moves revealed the model’s limited learning structure. Finally, during the Deployment & Live Performance stage, the model is integrated into real-world applications, and its performance is monitored. It is important for systems dealing with big data to manage real-time errors and to be scalable.\nAt the end of his talk, Mr. Demirtas discussed his doctoral research, which uses the Cellular Automaton Model to explore how autonomous vehicles can reduce traffic congestion. The goal is to minimize traffic buildup caused by stop-and-go driving or lane changes. The core objective of the thesis is to control when autonomous vehicles should merge, separate, and adjust their speed to optimize traffic flow. By properly guiding autonomous vehicles, maximum efficiency in traffic can be achieved.",
    "crumbs": [
      "Assignment 1"
    ]
  },
  {
    "objectID": "assignments/assignment-1.html#b-mtcars-dataset",
    "href": "assignments/assignment-1.html#b-mtcars-dataset",
    "title": "Assignment 1",
    "section": "(b) “mtcars” Dataset",
    "text": "(b) “mtcars” Dataset\nExploring Statistical Summaries with Custom Functions and Iteration Methods;\n\n\nShow the code\n#Writing a custom summary function\n\ncompute_stats&lt;-function(veri){\n  a&lt;-as.data.frame(matrix(c(quantile(veri),mean(veri),var(veri)),nrow=1,ncol=7))\n  colnames(a)&lt;-c(\"Min.\",\"1st Qu.\",\"Median\",\"3rd Qu.\",\"Max.\",\"Mean.\",\"Var.\")\n  a&lt;-as.list(a)\n  print(a)\n}\n\n\n\n\nShow the code\n#applying the function using a loop\n\nfor(i in 1:ncol(mtcars)){\n  n&lt;-data.frame(colnames(mtcars))\n  print(\"Summary for given data; \")\n  print(n[i,])\n  compute_stats(mtcars[,i])\n}\n\n\n[1] \"Summary for given data; \"\n[1] \"mpg\"\n$Min.\n[1] 10.4\n\n$`1st Qu.`\n[1] 15.425\n\n$Median\n[1] 19.2\n\n$`3rd Qu.`\n[1] 22.8\n\n$Max.\n[1] 33.9\n\n$Mean.\n[1] 20.09062\n\n$Var.\n[1] 36.3241\n\n[1] \"Summary for given data; \"\n[1] \"cyl\"\n$Min.\n[1] 4\n\n$`1st Qu.`\n[1] 4\n\n$Median\n[1] 6\n\n$`3rd Qu.`\n[1] 8\n\n$Max.\n[1] 8\n\n$Mean.\n[1] 6.1875\n\n$Var.\n[1] 3.189516\n\n[1] \"Summary for given data; \"\n[1] \"disp\"\n$Min.\n[1] 71.1\n\n$`1st Qu.`\n[1] 120.825\n\n$Median\n[1] 196.3\n\n$`3rd Qu.`\n[1] 326\n\n$Max.\n[1] 472\n\n$Mean.\n[1] 230.7219\n\n$Var.\n[1] 15360.8\n\n[1] \"Summary for given data; \"\n[1] \"hp\"\n$Min.\n[1] 52\n\n$`1st Qu.`\n[1] 96.5\n\n$Median\n[1] 123\n\n$`3rd Qu.`\n[1] 180\n\n$Max.\n[1] 335\n\n$Mean.\n[1] 146.6875\n\n$Var.\n[1] 4700.867\n\n[1] \"Summary for given data; \"\n[1] \"drat\"\n$Min.\n[1] 2.76\n\n$`1st Qu.`\n[1] 3.08\n\n$Median\n[1] 3.695\n\n$`3rd Qu.`\n[1] 3.92\n\n$Max.\n[1] 4.93\n\n$Mean.\n[1] 3.596563\n\n$Var.\n[1] 0.2858814\n\n[1] \"Summary for given data; \"\n[1] \"wt\"\n$Min.\n[1] 1.513\n\n$`1st Qu.`\n[1] 2.58125\n\n$Median\n[1] 3.325\n\n$`3rd Qu.`\n[1] 3.61\n\n$Max.\n[1] 5.424\n\n$Mean.\n[1] 3.21725\n\n$Var.\n[1] 0.957379\n\n[1] \"Summary for given data; \"\n[1] \"qsec\"\n$Min.\n[1] 14.5\n\n$`1st Qu.`\n[1] 16.8925\n\n$Median\n[1] 17.71\n\n$`3rd Qu.`\n[1] 18.9\n\n$Max.\n[1] 22.9\n\n$Mean.\n[1] 17.84875\n\n$Var.\n[1] 3.193166\n\n[1] \"Summary for given data; \"\n[1] \"vs\"\n$Min.\n[1] 0\n\n$`1st Qu.`\n[1] 0\n\n$Median\n[1] 0\n\n$`3rd Qu.`\n[1] 1\n\n$Max.\n[1] 1\n\n$Mean.\n[1] 0.4375\n\n$Var.\n[1] 0.2540323\n\n[1] \"Summary for given data; \"\n[1] \"am\"\n$Min.\n[1] 0\n\n$`1st Qu.`\n[1] 0\n\n$Median\n[1] 0\n\n$`3rd Qu.`\n[1] 1\n\n$Max.\n[1] 1\n\n$Mean.\n[1] 0.40625\n\n$Var.\n[1] 0.2489919\n\n[1] \"Summary for given data; \"\n[1] \"gear\"\n$Min.\n[1] 3\n\n$`1st Qu.`\n[1] 3\n\n$Median\n[1] 4\n\n$`3rd Qu.`\n[1] 4\n\n$Max.\n[1] 5\n\n$Mean.\n[1] 3.6875\n\n$Var.\n[1] 0.5443548\n\n[1] \"Summary for given data; \"\n[1] \"carb\"\n$Min.\n[1] 1\n\n$`1st Qu.`\n[1] 2\n\n$Median\n[1] 2\n\n$`3rd Qu.`\n[1] 4\n\n$Max.\n[1] 8\n\n$Mean.\n[1] 2.8125\n\n$Var.\n[1] 2.608871\n\n\n\n\nShow the code\n#An alternative approach with sapply and apply.\nsapply(mtcars,compute_stats)\n\n\n$Min.\n[1] 10.4\n\n$`1st Qu.`\n[1] 15.425\n\n$Median\n[1] 19.2\n\n$`3rd Qu.`\n[1] 22.8\n\n$Max.\n[1] 33.9\n\n$Mean.\n[1] 20.09062\n\n$Var.\n[1] 36.3241\n\n$Min.\n[1] 4\n\n$`1st Qu.`\n[1] 4\n\n$Median\n[1] 6\n\n$`3rd Qu.`\n[1] 8\n\n$Max.\n[1] 8\n\n$Mean.\n[1] 6.1875\n\n$Var.\n[1] 3.189516\n\n$Min.\n[1] 71.1\n\n$`1st Qu.`\n[1] 120.825\n\n$Median\n[1] 196.3\n\n$`3rd Qu.`\n[1] 326\n\n$Max.\n[1] 472\n\n$Mean.\n[1] 230.7219\n\n$Var.\n[1] 15360.8\n\n$Min.\n[1] 52\n\n$`1st Qu.`\n[1] 96.5\n\n$Median\n[1] 123\n\n$`3rd Qu.`\n[1] 180\n\n$Max.\n[1] 335\n\n$Mean.\n[1] 146.6875\n\n$Var.\n[1] 4700.867\n\n$Min.\n[1] 2.76\n\n$`1st Qu.`\n[1] 3.08\n\n$Median\n[1] 3.695\n\n$`3rd Qu.`\n[1] 3.92\n\n$Max.\n[1] 4.93\n\n$Mean.\n[1] 3.596563\n\n$Var.\n[1] 0.2858814\n\n$Min.\n[1] 1.513\n\n$`1st Qu.`\n[1] 2.58125\n\n$Median\n[1] 3.325\n\n$`3rd Qu.`\n[1] 3.61\n\n$Max.\n[1] 5.424\n\n$Mean.\n[1] 3.21725\n\n$Var.\n[1] 0.957379\n\n$Min.\n[1] 14.5\n\n$`1st Qu.`\n[1] 16.8925\n\n$Median\n[1] 17.71\n\n$`3rd Qu.`\n[1] 18.9\n\n$Max.\n[1] 22.9\n\n$Mean.\n[1] 17.84875\n\n$Var.\n[1] 3.193166\n\n$Min.\n[1] 0\n\n$`1st Qu.`\n[1] 0\n\n$Median\n[1] 0\n\n$`3rd Qu.`\n[1] 1\n\n$Max.\n[1] 1\n\n$Mean.\n[1] 0.4375\n\n$Var.\n[1] 0.2540323\n\n$Min.\n[1] 0\n\n$`1st Qu.`\n[1] 0\n\n$Median\n[1] 0\n\n$`3rd Qu.`\n[1] 1\n\n$Max.\n[1] 1\n\n$Mean.\n[1] 0.40625\n\n$Var.\n[1] 0.2489919\n\n$Min.\n[1] 3\n\n$`1st Qu.`\n[1] 3\n\n$Median\n[1] 4\n\n$`3rd Qu.`\n[1] 4\n\n$Max.\n[1] 5\n\n$Mean.\n[1] 3.6875\n\n$Var.\n[1] 0.5443548\n\n$Min.\n[1] 1\n\n$`1st Qu.`\n[1] 2\n\n$Median\n[1] 2\n\n$`3rd Qu.`\n[1] 4\n\n$Max.\n[1] 8\n\n$Mean.\n[1] 2.8125\n\n$Var.\n[1] 2.608871\n\n\n        mpg      cyl      disp     hp       drat      wt       qsec    \nMin.    10.4     4        71.1     52       2.76      1.513    14.5    \n1st Qu. 15.425   4        120.825  96.5     3.08      2.58125  16.8925 \nMedian  19.2     6        196.3    123      3.695     3.325    17.71   \n3rd Qu. 22.8     8        326      180      3.92      3.61     18.9    \nMax.    33.9     8        472      335      4.93      5.424    22.9    \nMean.   20.09062 6.1875   230.7219 146.6875 3.596563  3.21725  17.84875\nVar.    36.3241  3.189516 15360.8  4700.867 0.2858814 0.957379 3.193166\n        vs        am        gear      carb    \nMin.    0         0         3         1       \n1st Qu. 0         0         3         2       \nMedian  0         0         4         2       \n3rd Qu. 1         1         4         4       \nMax.    1         1         5         8       \nMean.   0.4375    0.40625   3.6875    2.8125  \nVar.    0.2540323 0.2489919 0.5443548 2.608871\n\n\nShow the code\napply(mtcars,2,compute_stats)\n\n\n$Min.\n[1] 10.4\n\n$`1st Qu.`\n[1] 15.425\n\n$Median\n[1] 19.2\n\n$`3rd Qu.`\n[1] 22.8\n\n$Max.\n[1] 33.9\n\n$Mean.\n[1] 20.09062\n\n$Var.\n[1] 36.3241\n\n$Min.\n[1] 4\n\n$`1st Qu.`\n[1] 4\n\n$Median\n[1] 6\n\n$`3rd Qu.`\n[1] 8\n\n$Max.\n[1] 8\n\n$Mean.\n[1] 6.1875\n\n$Var.\n[1] 3.189516\n\n$Min.\n[1] 71.1\n\n$`1st Qu.`\n[1] 120.825\n\n$Median\n[1] 196.3\n\n$`3rd Qu.`\n[1] 326\n\n$Max.\n[1] 472\n\n$Mean.\n[1] 230.7219\n\n$Var.\n[1] 15360.8\n\n$Min.\n[1] 52\n\n$`1st Qu.`\n[1] 96.5\n\n$Median\n[1] 123\n\n$`3rd Qu.`\n[1] 180\n\n$Max.\n[1] 335\n\n$Mean.\n[1] 146.6875\n\n$Var.\n[1] 4700.867\n\n$Min.\n[1] 2.76\n\n$`1st Qu.`\n[1] 3.08\n\n$Median\n[1] 3.695\n\n$`3rd Qu.`\n[1] 3.92\n\n$Max.\n[1] 4.93\n\n$Mean.\n[1] 3.596563\n\n$Var.\n[1] 0.2858814\n\n$Min.\n[1] 1.513\n\n$`1st Qu.`\n[1] 2.58125\n\n$Median\n[1] 3.325\n\n$`3rd Qu.`\n[1] 3.61\n\n$Max.\n[1] 5.424\n\n$Mean.\n[1] 3.21725\n\n$Var.\n[1] 0.957379\n\n$Min.\n[1] 14.5\n\n$`1st Qu.`\n[1] 16.8925\n\n$Median\n[1] 17.71\n\n$`3rd Qu.`\n[1] 18.9\n\n$Max.\n[1] 22.9\n\n$Mean.\n[1] 17.84875\n\n$Var.\n[1] 3.193166\n\n$Min.\n[1] 0\n\n$`1st Qu.`\n[1] 0\n\n$Median\n[1] 0\n\n$`3rd Qu.`\n[1] 1\n\n$Max.\n[1] 1\n\n$Mean.\n[1] 0.4375\n\n$Var.\n[1] 0.2540323\n\n$Min.\n[1] 0\n\n$`1st Qu.`\n[1] 0\n\n$Median\n[1] 0\n\n$`3rd Qu.`\n[1] 1\n\n$Max.\n[1] 1\n\n$Mean.\n[1] 0.40625\n\n$Var.\n[1] 0.2489919\n\n$Min.\n[1] 3\n\n$`1st Qu.`\n[1] 3\n\n$Median\n[1] 4\n\n$`3rd Qu.`\n[1] 4\n\n$Max.\n[1] 5\n\n$Mean.\n[1] 3.6875\n\n$Var.\n[1] 0.5443548\n\n$Min.\n[1] 1\n\n$`1st Qu.`\n[1] 2\n\n$Median\n[1] 2\n\n$`3rd Qu.`\n[1] 4\n\n$Max.\n[1] 8\n\n$Mean.\n[1] 2.8125\n\n$Var.\n[1] 2.608871\n\n\n$mpg\n$mpg$Min.\n[1] 10.4\n\n$mpg$`1st Qu.`\n[1] 15.425\n\n$mpg$Median\n[1] 19.2\n\n$mpg$`3rd Qu.`\n[1] 22.8\n\n$mpg$Max.\n[1] 33.9\n\n$mpg$Mean.\n[1] 20.09062\n\n$mpg$Var.\n[1] 36.3241\n\n\n$cyl\n$cyl$Min.\n[1] 4\n\n$cyl$`1st Qu.`\n[1] 4\n\n$cyl$Median\n[1] 6\n\n$cyl$`3rd Qu.`\n[1] 8\n\n$cyl$Max.\n[1] 8\n\n$cyl$Mean.\n[1] 6.1875\n\n$cyl$Var.\n[1] 3.189516\n\n\n$disp\n$disp$Min.\n[1] 71.1\n\n$disp$`1st Qu.`\n[1] 120.825\n\n$disp$Median\n[1] 196.3\n\n$disp$`3rd Qu.`\n[1] 326\n\n$disp$Max.\n[1] 472\n\n$disp$Mean.\n[1] 230.7219\n\n$disp$Var.\n[1] 15360.8\n\n\n$hp\n$hp$Min.\n[1] 52\n\n$hp$`1st Qu.`\n[1] 96.5\n\n$hp$Median\n[1] 123\n\n$hp$`3rd Qu.`\n[1] 180\n\n$hp$Max.\n[1] 335\n\n$hp$Mean.\n[1] 146.6875\n\n$hp$Var.\n[1] 4700.867\n\n\n$drat\n$drat$Min.\n[1] 2.76\n\n$drat$`1st Qu.`\n[1] 3.08\n\n$drat$Median\n[1] 3.695\n\n$drat$`3rd Qu.`\n[1] 3.92\n\n$drat$Max.\n[1] 4.93\n\n$drat$Mean.\n[1] 3.596563\n\n$drat$Var.\n[1] 0.2858814\n\n\n$wt\n$wt$Min.\n[1] 1.513\n\n$wt$`1st Qu.`\n[1] 2.58125\n\n$wt$Median\n[1] 3.325\n\n$wt$`3rd Qu.`\n[1] 3.61\n\n$wt$Max.\n[1] 5.424\n\n$wt$Mean.\n[1] 3.21725\n\n$wt$Var.\n[1] 0.957379\n\n\n$qsec\n$qsec$Min.\n[1] 14.5\n\n$qsec$`1st Qu.`\n[1] 16.8925\n\n$qsec$Median\n[1] 17.71\n\n$qsec$`3rd Qu.`\n[1] 18.9\n\n$qsec$Max.\n[1] 22.9\n\n$qsec$Mean.\n[1] 17.84875\n\n$qsec$Var.\n[1] 3.193166\n\n\n$vs\n$vs$Min.\n[1] 0\n\n$vs$`1st Qu.`\n[1] 0\n\n$vs$Median\n[1] 0\n\n$vs$`3rd Qu.`\n[1] 1\n\n$vs$Max.\n[1] 1\n\n$vs$Mean.\n[1] 0.4375\n\n$vs$Var.\n[1] 0.2540323\n\n\n$am\n$am$Min.\n[1] 0\n\n$am$`1st Qu.`\n[1] 0\n\n$am$Median\n[1] 0\n\n$am$`3rd Qu.`\n[1] 1\n\n$am$Max.\n[1] 1\n\n$am$Mean.\n[1] 0.40625\n\n$am$Var.\n[1] 0.2489919\n\n\n$gear\n$gear$Min.\n[1] 3\n\n$gear$`1st Qu.`\n[1] 3\n\n$gear$Median\n[1] 4\n\n$gear$`3rd Qu.`\n[1] 4\n\n$gear$Max.\n[1] 5\n\n$gear$Mean.\n[1] 3.6875\n\n$gear$Var.\n[1] 0.5443548\n\n\n$carb\n$carb$Min.\n[1] 1\n\n$carb$`1st Qu.`\n[1] 2\n\n$carb$Median\n[1] 2\n\n$carb$`3rd Qu.`\n[1] 4\n\n$carb$Max.\n[1] 8\n\n$carb$Mean.\n[1] 2.8125\n\n$carb$Var.\n[1] 2.608871",
    "crumbs": [
      "Assignment 1"
    ]
  },
  {
    "objectID": "assignments/assignment-1.html#c-na_example-dataset",
    "href": "assignments/assignment-1.html#c-na_example-dataset",
    "title": "Assignment 1",
    "section": "(c) “na_example” Dataset",
    "text": "(c) “na_example” Dataset\nNA (missing) values\n\n\nShow the code\n#install.packages(dslabs)\nlibrary(dslabs)\nog_dataset&lt;-na_example\nprint(\"Our dataset:\")\n\n\n[1] \"Our dataset:\"\n\n\nShow the code\nprint(og_dataset)\n\n\n   [1]  2  1  3  2  1  3  1  4  3  2  2 NA  2  2  1  4 NA  1  1  2  1  2  2  1\n  [25]  2  5 NA  2  2  3  1  2  4  1  1  1  4  5  2  3  4  1  2  4  1  1  2  1\n  [49]  5 NA NA NA  1  1  5  1  3  1 NA  4  4  7  3  2 NA NA  1 NA  4  1  2  2\n  [73]  3  2  1  2  2  4  3  4  2  3  1  3  2  1  1  1  3  1 NA  3  1  2  2  1\n  [97]  2  2  1  1  4  1  1  2  3  3  2  2  3  3  3  4  1  1  1  2 NA  4  3  4\n [121]  3  1  2  1 NA NA NA NA  1  5  1  2  1  3  5  3  2  2 NA NA NA NA  3  5\n [145]  3  1  1  4  2  4  3  3 NA  2  3  2  6 NA  1  1  2  2  1  3  1  1  5 NA\n [169] NA  2  4 NA  2  5  1  4  3  3 NA  4  3  1  4  1  1  3  1  1 NA NA  3  5\n [193]  2  2  2  3  1  2  2  3  2  1 NA  2 NA  1 NA NA  2  1  1 NA  3 NA  1  2\n [217]  2  1  3  2  2  1  1  2  3  1  1  1  4  3  4  2  2  1  4  1 NA  5  1  4\n [241] NA  3 NA NA  1  1  5  2  3  3  2  4 NA  3  2  5 NA  2  3  4  6  2  2  2\n [265] NA  2 NA  2 NA  3  3  2  2  4  3  1  4  2 NA  2  4 NA  6  2  3  1 NA  2\n [289]  2 NA  1  1  3  2  3  3  1 NA  1  4  2  1  1  3  2  1  2  3  1 NA  2  3\n [313]  3  2  1  2  3  5  5  1  2  3  3  1 NA NA  1  2  4 NA  2  1  1  1  3  2\n [337]  1  1  3  4 NA  1  2  1  1  3  3 NA  1  1  3  5  3  2  3  4  1  4  3  1\n [361] NA  2  1  2  2  1  2  2  6  1  2  4  5 NA  3  4  2  1  1  4  2  1  1  1\n [385]  1  2  1  4  4  1  3 NA  3  3 NA  2 NA  1  2  1  1  4  2  1  4  4 NA  1\n [409]  2 NA  3  2  2  2  1  4  3  6  1  2  3  1  3  2  2  2  1  1  3  2  1  1\n [433]  1  3  2  2 NA  4  4  4  1  1 NA  4  3 NA  1  3  1  3  2  4  2  2  2  3\n [457]  2  1  4  3 NA  1  4  3  1  3  2 NA  3 NA  1  3  1  4  1  1  1  2  4  3\n [481]  1  2  2  2  3  2  3  1  1 NA  3  2  1  1  2 NA  2  2  2  3  3  1  1  2\n [505] NA  1  2  1  1  3  3  1  3  1  1  1  1  1  2  5  1  1  2  2  1  1 NA  1\n [529]  4  1  2  4  1  3  2 NA  1  1 NA  2  1  1  4  2  3  3  1  5  3  1  1  2\n [553] NA  1  1  3  1  3  2  4 NA  2  3  2  1  2  1  1  1  2  2  3  1  5  2 NA\n [577]  2 NA  3  2  2  2  1  5  3  2  3  1 NA  3  1  2  2  2  1  2  2  4 NA  6\n [601]  1  2 NA  1  1  2  2  3 NA  3  2  3  3  4  2 NA  2 NA  4 NA  1  1  2  2\n [625]  3  1  1  1  3 NA  2  5 NA  7  1 NA  4  3  3  1 NA  1  1  1  1  3  2  4\n [649]  2  2  3 NA NA  1  4  3  2  2  2  3  2  4  2  2  4 NA NA NA  6  3  3  1\n [673]  4  4  2  1 NA  1  6 NA  3  3  2  1  1  6 NA  1  5  1 NA  2  6  2 NA  4\n [697]  1  3  1  2 NA  1  1  3  1  2  4  2  1  3  2  4  3  2  2  1  1  5  6  4\n [721]  2  2  2  2  4 NA  1  2  2  2  2  4  5 NA NA NA  4  3  3  3  2  4  2  4\n [745] NA NA NA NA  2  1 NA  2  4  3  2 NA  2  3  1  3  4 NA  1  2  1  2 NA  3\n [769]  1  2  1  2  1  2  1  2  2  2  2  1  1  3  3  1  3  4  3 NA NA  4  2  3\n [793]  2  1  3  2  4  2  2  3  1  2  4  3  3  4 NA  1  4  2  1  1  1  3  1  5\n [817]  2  2  4  2 NA  1  3  1  2 NA  1  2  1  2  1 NA  1  3  2  3  2 NA  2  1\n [841]  4  2 NA NA NA  2  4  2 NA NA  3  1 NA  5  5  2  2  2 NA  2  1  3  1  3\n [865]  2  4  2  4 NA  4  1  2  3  2  3  3  2  3  2  2  2  1  3  2  4  2 NA  3\n [889]  3  2  2 NA NA  3  2  1  2  4  1  1  1  1  4  3  2 NA  3  2 NA  1 NA  3\n [913]  2  1  1  1  2 NA  2  2  3  3  2 NA NA  4  5  2  2  2  1  2  3  1  3  3\n [937]  4  3 NA  1  1  1 NA  4  3  5  1  1  2 NA  2  2  2  2  5  2  2  3  1  2\n [961]  3 NA  1  2 NA NA  2 NA  3  1  1  2  5  3  5  1  1  4 NA  2  1  3  1  1\n [985]  2  4  3  3  3 NA  1  1  2  2  1  1  2  2 NA  2\n\n\nShow the code\n#Total count of NA values \nsum&lt;-0\nfor(i in 1:1000){\nifelse(is.na(og_dataset[i])=='TRUE',sum&lt;-sum+1,sum&lt;-sum)\n}\nprint(\"Total count of NA values\")\n\n\n[1] \"Total count of NA values\"\n\n\nShow the code\nprint(sum)\n\n\n[1] 145\n\n\nShow the code\n# Index positions of NA values\nindex&lt;-matrix(data=rep(0,sum))\nb&lt;-1\nfor(i in 1:1000){\nif(is.na(og_dataset[i])=='TRUE'){\n  index[b]&lt;-i\n  b&lt;-b+1\n  }\n}\nprint(\"Index positions of NA values\")\n\n\n[1] \"Index positions of NA values\"\n\n\nShow the code\nprint(index)\n\n\n       [,1]\n  [1,]   12\n  [2,]   17\n  [3,]   27\n  [4,]   50\n  [5,]   51\n  [6,]   52\n  [7,]   59\n  [8,]   65\n  [9,]   66\n [10,]   68\n [11,]   91\n [12,]  117\n [13,]  125\n [14,]  126\n [15,]  127\n [16,]  128\n [17,]  139\n [18,]  140\n [19,]  141\n [20,]  142\n [21,]  153\n [22,]  158\n [23,]  168\n [24,]  169\n [25,]  172\n [26,]  179\n [27,]  189\n [28,]  190\n [29,]  203\n [30,]  205\n [31,]  207\n [32,]  208\n [33,]  212\n [34,]  214\n [35,]  237\n [36,]  241\n [37,]  243\n [38,]  244\n [39,]  253\n [40,]  257\n [41,]  265\n [42,]  267\n [43,]  269\n [44,]  279\n [45,]  282\n [46,]  287\n [47,]  290\n [48,]  298\n [49,]  310\n [50,]  325\n [51,]  326\n [52,]  330\n [53,]  341\n [54,]  348\n [55,]  361\n [56,]  374\n [57,]  392\n [58,]  395\n [59,]  397\n [60,]  407\n [61,]  410\n [62,]  437\n [63,]  443\n [64,]  446\n [65,]  461\n [66,]  468\n [67,]  470\n [68,]  490\n [69,]  496\n [70,]  505\n [71,]  527\n [72,]  536\n [73,]  539\n [74,]  553\n [75,]  561\n [76,]  576\n [77,]  578\n [78,]  589\n [79,]  599\n [80,]  603\n [81,]  609\n [82,]  616\n [83,]  618\n [84,]  620\n [85,]  630\n [86,]  633\n [87,]  636\n [88,]  641\n [89,]  652\n [90,]  653\n [91,]  666\n [92,]  667\n [93,]  668\n [94,]  677\n [95,]  680\n [96,]  687\n [97,]  691\n [98,]  695\n [99,]  701\n[100,]  726\n[101,]  734\n[102,]  735\n[103,]  736\n[104,]  745\n[105,]  746\n[106,]  747\n[107,]  748\n[108,]  751\n[109,]  756\n[110,]  762\n[111,]  767\n[112,]  788\n[113,]  789\n[114,]  807\n[115,]  821\n[116,]  826\n[117,]  832\n[118,]  838\n[119,]  843\n[120,]  844\n[121,]  845\n[122,]  849\n[123,]  850\n[124,]  853\n[125,]  859\n[126,]  869\n[127,]  887\n[128,]  892\n[129,]  893\n[130,]  906\n[131,]  909\n[132,]  911\n[133,]  918\n[134,]  924\n[135,]  925\n[136,]  939\n[137,]  943\n[138,]  950\n[139,]  962\n[140,]  965\n[141,]  966\n[142,]  968\n[143,]  979\n[144,]  990\n[145,]  999\n\n\nShow the code\n#Mean and standard deviation of dataset (ignore NA s in calculations)\nprint(\"Mean and St.Dev. of original data set\")\n\n\n[1] \"Mean and St.Dev. of original data set\"\n\n\nShow the code\nprint(mean(og_dataset,na.rm=TRUE))#na.rm=TRUE means ignoring NA values in computation\n\n\n[1] 2.301754\n\n\nShow the code\nprint(sd(og_dataset,na.rm=TRUE))\n\n\n[1] 1.22338\n\n\nShow the code\n#Handling missing values\n#Version1\nv1_dataset&lt;-matrix(data=rep(0,1000))\nv2_dataset&lt;-matrix(data=rep(0,1000))\nrandom&lt;-(sample(1:1000,1))\nfor(i in 1:1000){\nifelse(is.na(og_dataset[i])==TRUE,(v1_dataset[i]&lt;-median(og_dataset,na.rm = TRUE))&&(v2_dataset[i]&lt;-og_dataset[random]),(v1_dataset[i]&lt;-og_dataset[i])&&(v2_dataset[i]&lt;-og_dataset[i]))\n }\n\n#Compare the results\nprint(\"Mean and St.Dev. of Version 1 data set\")\n\n\n[1] \"Mean and St.Dev. of Version 1 data set\"\n\n\nShow the code\nmean(v1_dataset)\n\n\n[1] 2.258\n\n\nShow the code\nsd(v1_dataset)\n\n\n[1] 1.136102\n\n\nShow the code\nprint(\"Mean and St.Dev. of Version 2 data set\")\n\n\n[1] \"Mean and St.Dev. of Version 2 data set\"\n\n\nShow the code\nmean(v2_dataset)\n\n\n[1] 2.258\n\n\nShow the code\nsd(v2_dataset)\n\n\n[1] 1.136102\n\n\nShow the code\nprint(\"Mean and St.Dev. of original data set\")\n\n\n[1] \"Mean and St.Dev. of original data set\"\n\n\nShow the code\nmean(og_dataset,na.rm=TRUE)\n\n\n[1] 2.301754\n\n\nShow the code\nsd(og_dataset,na.rm=TRUE)\n\n\n[1] 1.22338\n\n\nThe mean and standard deviation values of different datasets should not differ significantly but the median statistic can carry more information about the distribution of the data, because of that the dataset produced according to Version 1 may be preferred.",
    "crumbs": [
      "Assignment 1"
    ]
  }
]